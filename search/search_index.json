{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Helpful codes","text":""},{"location":"#contents","title":"Contents","text":"<ol> <li>CLI (Command Line Interface)</li> </ol>"},{"location":"01-basics/01-argument-parser/","title":"Argument Parser in Python","text":""},{"location":"01-basics/01-argument-parser/#python-argparse-concise-notes","title":"Python argparse - Concise Notes","text":"<p><code>argparse</code> is a Python library for parsing command-line arguments. It provides a simple interface to define, process, and handle arguments.</p>"},{"location":"01-basics/01-argument-parser/#basic-usage","title":"Basic Usage","text":"<ol> <li> <p>Setup <pre><code>import argparse\nparser = argparse.ArgumentParser(description=\"A simple script\")\n</code></pre></p> </li> <li> <p>Adding Arguments</p> </li> <li> <p>Positional Argument: Required, order matters      <pre><code>parser.add_argument(\"filename\", help=\"File to process\")\n</code></pre></p> </li> <li> <p>Optional Argument: Starts with <code>--</code> or <code>-</code>, order doesn\u2019t matter.      <pre><code>parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable verbose output\")\nparser.add_argument(\"-n\", \"--number\", type=int, default=1, help=\"Number of iterations\")\n</code></pre></p> </li> <li> <p>Parsing Arguments</p> </li> </ol> <pre><code>args = parser.parse_args()\nprint(args.filename)      # Positional argument\nprint(args.verbose)       # True/False (store_true)\nprint(args.number)        # Integer value (default: 1)\n</code></pre>"},{"location":"01-basics/01-argument-parser/#key-argument-settings","title":"Key Argument Settings","text":"<ol> <li>Positional Arguments:</li> <li>No special prefix.</li> <li> <p>Example: <code>python script.py input.txt</code></p> </li> <li> <p>Optional Arguments:</p> </li> <li>Use <code>-</code> or <code>--</code>.</li> <li> <p>Example: <code>python script.py --verbose</code></p> </li> <li> <p>Argument Types:</p> </li> <li>Specify with <code>type</code> (e.g., <code>int</code>, <code>float</code>, <code>str</code>).</li> <li> <p>Example:      <pre><code>parser.add_argument(\"--value\", type=float, help=\"A float value\")\n</code></pre></p> </li> <li> <p>Default Values:</p> </li> <li>Use <code>default</code>.</li> <li> <p>Example:      <pre><code>parser.add_argument(\"--name\", default=\"User\", help=\"Default name\")\n</code></pre></p> </li> <li> <p>Boolean Flags:</p> </li> <li>Use <code>action=\"store_true\"</code> or <code>action=\"store_false\"</code>.</li> <li> <p>Example:</p> <pre><code>parser.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug mode\")\n</code></pre> </li> </ol>"},{"location":"01-basics/01-argument-parser/#example-usage","title":"Example Usage","text":"<p>Script:</p> <pre><code>import argparse\n\nparser = argparse.ArgumentParser(description=\"Demo script\")\nparser.add_argument(\"filename\", help=\"Input file name\")\nparser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Enable verbosity\")\nparser.add_argument(\"-n\", \"--number\", type=int, default=10, help=\"Number of items\")\nargs = parser.parse_args()\n\nprint(f\"Filename: {args.filename}\")\nprint(f\"Verbose: {args.verbose}\")\nprint(f\"Number: {args.number}\")\n</code></pre> <p>Run:</p> <pre><code>python script.py file.txt --verbose -n 5\n</code></pre> <p>Output:</p> <pre><code>Filename: file.txt\nVerbose: True\nNumber: 5\n</code></pre>"},{"location":"01-basics/01-argument-parser/#common-methods","title":"Common Methods","text":"<ol> <li><code>parser.add_argument()</code>: Define arguments.</li> <li><code>parser.add_subparsers()</code>: Create subcommands.</li> <li><code>parser.set_defaults()</code>: Set default functions for arguments.</li> <li><code>parser.parse_args()</code>: Parse command-line inputs.</li> </ol>"},{"location":"01-basics/01-argument-parser/#cli-with-subcommands","title":"CLI with subcommands","text":"<pre><code>from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser, RawTextHelpFormatter\n\n\nclass DeepFormatter(ArgumentDefaultsHelpFormatter, RawTextHelpFormatter): ...\n\n\ndef parse_args():\n    parser = ArgumentParser(\n        description=\"A simple script to demonstrate argument parsing.\",\n        formatter_class=DeepFormatter,\n    )\n    # Top-level subparser\n    # dest value is used to check which command was called\n    # if `dest=meow`, then `args.meow` will be set to the subcommand called (cache, or optimize)\n    subparsers = parser.add_subparsers(dest=\"command\", title=\"Commands\")\n\n    cache_parser = subparsers.add_parser(\n        \"cache\", help=\"Cache the dataset\", formatter_class=DeepFormatter\n    )\n    cache_parser.add_argument(\n        \"--cache-dir\", type=str, help=\"Directory to cache the dataset\"\n    )\n    cache_parser.add_argument(\n        \"--cache-size\", type=int, default=100, help=\"Size of the cache in MB\"\n    )\n    cache_parser.set_defaults(func=handle_cache)\n    optimize_parser = subparsers.add_parser(\n        \"optimize\", help=\"Optimize the dataset\", formatter_class=DeepFormatter\n    )\n    optimize_parser.add_argument(\n        \"--optimize-level\", type=int, default=1, help=\"Level of optimization (1-3)\"\n    )\n    optimize_parser.set_defaults(func=handle_optimize)\n    optimize_parser.add_argument(\n        \"--optimize-strategy\",\n        type=str,\n        choices=[\"fast\", \"balanced\", \"thorough\"],\n        default=\"balanced\",\n        help=\"Strategy for optimization\",\n    )\n    return parser.parse_args(), parser\n\ndef handle_cache(args):\n    print(f\"running command: {args.command}\")\n    print(f\"Caching dataset in {args.cache_dir} with size {args.cache_size}MB\")\n\ndef handle_optimize(args):\n    print(f\"Optimizing dataset with level {args.optimize_level} and strategy {args.optimize_strategy}\")\n\n\ndef main():\n    args, parser = parse_args()\n    if hasattr(args, \"func\"):\n        args.func(args)\n    else:\n        parser.print_help()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"01-basics/01-argument-parser/#tips","title":"Tips","text":"<ul> <li>Use <code>help</code> for clear CLI documentation.</li> <li>Default type is <code>str</code> if not specified.</li> <li>Boolean flags (<code>store_true</code>) are ideal for toggles.</li> </ul> <p>For most cases, this basic usage suffices!</p>"},{"location":"01-basics/02-cli/","title":"Command Line Interface (CLI)","text":"<ul> <li>Assumes you already have a python project with <code>__init__.py</code> file and <code>pyproject.toml</code> or <code>setup.py</code> file.</li> </ul> <pre><code>src/\n\u251c\u2500\u2500 mylib/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 cli.py\n\u2514\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 setup.py\n</code></pre>"},{"location":"01-basics/02-cli/#steps","title":"Steps \u2b50\ufe0f","text":""},{"location":"01-basics/02-cli/#step-1-create-a-cli-file","title":"Step 1: Create a CLI file","text":"<p>Create a new file named <code>cli.py</code> in your library directory (e.g., <code>mylib/cli.py</code>). This file will contain the logic for your command line interface.</p>"},{"location":"01-basics/02-cli/#step-2-implement-the-cli-logic","title":"Step 2: Implement the CLI logic","text":"<pre><code># mylib/cli.py\nimport argparse\nfrom mylib import main_logic  # your core logic\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"MyLib CLI\")\n    parser.add_argument(\"--input\", type=str, required=True)\n    args = parser.parse_args()\n\n    result = main_logic(args.input)\n    print(result)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"01-basics/02-cli/#step-3-define-a-cli-entry-point-in-pyprojecttoml-or-setuppy","title":"Step 3: Define a CLI Entry Point in <code>pyproject.toml</code> or <code>setup.py</code>","text":"<ul> <li> <p>We need to <code>define which function should be called</code> when the CLI command is executed. This is done by <code>specifying an entry point</code> in your <code>pyproject.toml</code> or <code>setup.py</code> file.</p> </li> <li> <p>For <code>pyproject.toml</code>:</p> </li> </ul> <pre><code>[project.scripts]\nmylib = \"mylib.cli:main\"\n</code></pre> <ul> <li>For <code>setup.py</code>:</li> </ul> <pre><code>entry_points={\n    \"console_scripts\": [\n        \"mylib = mylib.cli:main\"\n    ],\n}\n</code></pre>"},{"location":"01-basics/02-cli/#step-4-install-your-package","title":"Step 4: Install your package","text":"<ul> <li>Now if you install your package in editable mode using <code>pip install -e .</code> or use <code>pip install package_name</code>, you can run your CLI with the command:</li> </ul> <pre><code>mylib --input \"your_input_value\"\n</code></pre> <p>This will execute the <code>entrypoint</code> that you defined in <code>pyproject.toml</code> or <code>setup.py</code>.</p>"},{"location":"01-basics/02-cli/#suggestions","title":"Suggestions \u2705","text":"<ul> <li>Use argparse: It is a powerful library for parsing command line arguments and options.</li> <li>Use click: If you want a more advanced CLI, consider using the <code>click</code> library, which provides a more user-friendly interface for building command line applications.</li> <li>Use typer: If you prefer type hints and want to create a CLI with less boilerplate, consider using <code>typer</code>, which is built on top of <code>click</code> and provides a more Pythonic way to define command line interfaces.</li> </ul>"},{"location":"01-basics/02-cli/#testing-cli","title":"Testing CLI \ud83e\udd13","text":"<ul> <li>If you're using <code>typer</code>, you can test your CLI using the <code>CliRunner</code> from <code>typer.testing</code>.</li> </ul> <p>typer testing</p> <pre><code>from typer.testing import CliRunner\n\nfrom litdata.cli import app\n\nrunner = CliRunner()\n\n\ndef test_litdata_help_command():\n    result = runner.invoke(app, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"LitData CLI\" in result.output\n    assert \"cache\" in result.output\n\n\ndef test_cache_path_command():\n    result = runner.invoke(app, [\"cache\", \"path\"])\n    assert result.exit_code == 0\n    assert \"Default cache directory\" in result.output\n\n\ndef test_cache_clear_command(tmp_path, monkeypatch):\n    result = runner.invoke(app, [\"cache\", \"clear\"])\n    assert result.exit_code == 0\n    assert \"cleared\" in result.output\n</code></pre>"},{"location":"01-basics/05-tqdm/","title":"TQDM","text":"<pre><code>pip install tqdm\n</code></pre>"},{"location":"01-basics/05-tqdm/#basic-usage","title":"Basic usage","text":"<pre><code>from tqdm import tqdm\nfor i in tqdm(range(10000)):\n    ...\n</code></pre>"},{"location":"01-basics/05-tqdm/#manually-update-tqdm","title":"Manually update <code>tqdm</code>","text":"<pre><code>import random\nimport time\nfrom tqdm.auto import tqdm as _tqdm\n\ntotal = 10\n\npbar = _tqdm(\n    desc=\"Progress\",\n    total=total,\n    smoothing=0,\n    position=-1,\n    mininterval=1,\n    leave=True,\n    dynamic_ncols=True,\n    unit=\"step\"\n)\n\nfor _ in range(10):\n    sleep_time = random.uniform(1, 1.5)  # Random sleep time between 0.5 and 1 second\n    time.sleep(sleep_time)\n    pbar.update(1)\n\npbar.close()\n</code></pre>"},{"location":"01-basics/06-walrus-operator/","title":"Walrus Operator","text":"<p>The walrus operator <code>:=</code> is a new operator in Python 3.8 that <code>assigns values to variables as part of an expression</code>.</p> <pre><code>numbers = [1, 2, 3, 4, 5]\n\nwhile (n := len(numbers)) &gt; 0:\n    print(numbers.pop())\n</code></pre>"},{"location":"01-basics/06-walrus-operator/#example-1","title":"Example 1","text":"<pre><code>sample_data = [\n    {\"userId\": 1, \"name\": \"rahul\", \"completed\": False},\n    {\"userId\": 1, \"name\": \"rohit\", \"completed\": False},\n    {\"userId\": 1, \"name\": \"ram\", \"completed\": False},\n    {\"userId\": 1, \"name\": \"ravan\", \"completed\": True}\n]\n\nprint(\"With Python 3.8 Walrus Operator:\")\nfor entry in sample_data:\n    if name := entry.get(\"name\"):\n        print(f'Found name: \"{name}\"')\n\nprint(\"Without Walrus operator:\")\nfor entry in sample_data:\n    name = entry.get(\"name\")\n    if name:\n        print(f'Found name: \"{name}\"')\n</code></pre>"},{"location":"01-basics/06-walrus-operator/#example-2","title":"Example 2","text":"<pre><code>## The below example is without Walrus Operator\nfoods = list()\nwhile True:\n  food = input(\"What food do you like?: \")\n  if food == \"quit\":\n    break\n    foods.append(food)\n\n# Below Approach uses Walrus Operator\nfoods1 = list()\nwhile (food := input(\"What food do you like:=  \")) != \"quit\":\n    foods.append(food)\n</code></pre>"},{"location":"01-basics/07-io-and-bytesio/","title":"IO &amp; BytesIO in Python","text":"<p>Python's built-in <code>io</code> module provides tools for handling text and binary streams efficiently.</p>"},{"location":"01-basics/07-io-and-bytesio/#types-of-streams","title":"Types of Streams","text":"<ol> <li>Text I/O (<code>TextIOBase</code>) \u2192 Handles text files (<code>.txt</code>, <code>.csv</code>, etc.).</li> <li>Binary I/O (<code>BufferedIOBase</code>) \u2192 Handles binary files (<code>.png</code>, <code>.mp4</code>, <code>.zip</code>, etc.).</li> <li>Raw I/O (<code>RawIOBase</code>) \u2192 Low-level access to files &amp; devices.</li> <li>In-Memory Streams (<code>BytesIO</code>, <code>StringIO</code>) \u2192 Simulate file-like objects in RAM.</li> </ol>"},{"location":"01-basics/07-io-and-bytesio/#bytesio","title":"<code>BytesIO</code>","text":"<p><code>io.BytesIO</code> is a file-like object that operates in memory instead of disk.</p> <ul> <li>Creating a <code>BytesIO</code> Object</li> </ul> <pre><code>import io\n\n# Creating a BytesIO object with binary data\nbyte_stream = io.BytesIO(b\"Hello, this is binary data!\")\n\n# Read the data\nprint(byte_stream.read())  # Output: b'Hello, this is binary data!'\n</code></pre> <ul> <li>Writing to <code>BytesIO</code></li> </ul> <pre><code>byte_stream = io.BytesIO()\nbyte_stream.write(b\"Python BytesIO Example\")\n\n# Reset cursor to the beginning before reading\nbyte_stream.seek(0)\nprint(byte_stream.read())  # Output: b'Python BytesIO Example'\n</code></pre> <ul> <li>Using <code>BytesIO</code> Like a File</li> </ul> <pre><code>with io.BytesIO() as byte_file:\n    byte_file.write(b\"Hello World!\")\n    byte_file.seek(0)  # Move back to start\n    print(byte_file.read())  # Output: b'Hello World!'\n</code></pre>"},{"location":"01-basics/07-io-and-bytesio/#writing-bytesio-to-a-file","title":"Writing <code>BytesIO</code> to a File","text":"<ul> <li>1\ufe0f\u20e3 Using <code>.getvalue()</code> (For small data)</li> </ul> <pre><code>byte_stream = io.BytesIO(b\"Binary Content\")\n\nwith open(\"output.bin\", \"wb\") as f:\n    f.write(byte_stream.getvalue())  # Extract all bytes and write to file\n</code></pre> <ul> <li>2\ufe0f\u20e3 Using <code>shutil.copyfileobj()</code> (For large data)</li> </ul> <pre><code>import shutil\n\nbyte_stream = io.BytesIO(b\"Large binary content...\")\n\nwith open(\"output_large.bin\", \"wb\") as f:\n    shutil.copyfileobj(byte_stream, f)  # Efficient copy without memory overhead\n</code></pre>"},{"location":"01-basics/07-io-and-bytesio/#reading-writing-binary-files-with-open","title":"Reading &amp; Writing Binary Files with <code>open()</code>","text":"<pre><code># Writing binary data to a file\nwith open(\"data.bin\", \"wb\") as f:\n    f.write(b\"Some binary data\")\n\n# Reading binary data from a file\nwith open(\"data.bin\", \"rb\") as f:\n    content = f.read()\n    print(content)  # Output: b'Some binary data'\n\n# reading file in 1000 bytes chunks\nwith open(\"data.bin\", \"rb\") as f:\n    while chunk := f.read(1000):\n        print(chunk)\n\n# download from cloud and save in 1000 bytes chunks\nwith self.fs.open(_file[\"name\"], \"rb\") as cloud_file, open(temp_path, \"wb\") as local_file:\n    # b\"\" is the sentinel value, pause when you get empty bytes\n    for chunk in iter(lambda: cloud_file.read(4096), b\"\"):  # Read in 4KB chunks\n        local_file.write(chunk)\n</code></pre>"},{"location":"01-basics/07-io-and-bytesio/#seeking-telling-in-binary-streams","title":"Seeking &amp; Telling in Binary Streams","text":"<ul> <li> <p><code>seek(offset, whence)</code> \u2192 Move the file pointer</p> </li> <li> <p><code>whence=0</code> \u2192 Start from the beginning (default)</p> </li> <li><code>whence=1</code> \u2192 Move relative to current position</li> <li> <p><code>whence=2</code> \u2192 Move relative to the end</p> </li> <li> <p>Example: Seeking &amp; Reading in Chunks</p> </li> </ul> <pre><code>with open(\"data.bin\", \"rb\") as f:\n    f.seek(5)  # Move to the 5th byte\n    print(f.read(10))  # Read next 10 bytes\n</code></pre> <ul> <li>Get Current Position with <code>tell()</code></li> </ul> <pre><code>with open(\"data.bin\", \"rb\") as f:\n    print(f.tell())  # Output: 0 (Start position)\n    f.read(5)\n    print(f.tell())  # Output: 5 (After reading 5 bytes)\n</code></pre> <ul> <li>Using truncate() to modify the file size</li> </ul> <p>io.truncate(size) is used to resize a file to a specific byte length. If size is smaller than the current file size, the file is truncated (cut off) at that point. If size is larger, the file is extended, and the new space is filled with null bytes (\\x00). It is useful for clearing files or adjusting their length without rewriting them.</p> <pre><code>with open(\"example.txt\", \"wb\") as f:\n    f.write(b\"Hello, World!\")\n    f.truncate(5)  # File now contains only \"Hello\"\n</code></pre> <p>Downloading a very large file very fast \ud83d\ude80</p> <ul> <li>To download a large file very fast, we can make a header request to get the file size bytes.</li> <li>Create a file and preallocate the size.</li> <li>Then start number of threads that will download their range in parallel.</li> <li>After downloading, each thread will write their range to the file.</li> </ul>"},{"location":"01-basics/07-io-and-bytesio/#handling-large-files-efficiently","title":"Handling Large Files Efficiently","text":"<ul> <li>Using <code>seek()</code> &amp; <code>read()</code> for Large Files</li> </ul> <pre><code>with open(\"large_file.bin\", \"rb\") as f:\n    chunk_size = 1024  # Read in 1KB chunks\n    while chunk := f.read(chunk_size):\n        process(chunk)  # Replace with your processing logic\n</code></pre>"},{"location":"01-basics/07-io-and-bytesio/#using-mmap-for-efficient-file-access","title":"Using <code>mmap</code> for Efficient File Access","text":"<ul> <li>Memory-mapped File for Large Binary Data</li> </ul> <pre><code>import mmap\n\nwith open(\"large_file.bin\", \"r+b\") as f:\n    mm = mmap.mmap(f.fileno(), 0)\n    print(mm[:100])  # Read first 100 bytes\n    mm.close()\n</code></pre> <p>\u2705 No RAM overhead even for 100GB+ files!</p>"},{"location":"01-basics/07-io-and-bytesio/#when-to-use-bytesio","title":"When to Use <code>BytesIO</code>?","text":"<ul> <li>\u2705 When you don't want to use disk I/O (temporary storage)</li> <li>\u2705 Handling binary data manipulation in memory</li> <li>\u2705 Simulating file objects for APIs that expect file-like input</li> </ul>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/","title":"Loops and Functions","text":""},{"location":"01-basics/02-data-structures/00-loops-and-functions/#loops","title":"Loops","text":"<pre><code># for loop with range, enumerate, zip\nfor i in range(10):\n    print(i)\n\nfor i, j in enumerate(['a', 'b', 'c']):\n    print(i, j)\n\nfor i, j in zip(['a', 'b', 'c'], ['x', 'y', 'z']):\n    print(i, j)\n</code></pre>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/#range","title":"Range","text":"<pre><code>x = range(10)\nprint(list(x))\n\nx = range(10, 20)\nprint(list(x))\n\nx = range(10, 20, 2)\nprint(list(x))\n</code></pre>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/#functions","title":"Functions","text":"<pre><code>def add(a, b):\n    return a + b\n\nadd(1, 2)\n</code></pre>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/#lambda","title":"Lambda","text":"<pre><code>square = lambda x: x * x\nsquare(2)\n</code></pre>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/#args-and-kwargs","title":"<code>*args</code> and <code>**kwargs</code>","text":"<pre><code>def add(*args):\n    return sum(args)\n\ndef sub(**kwargs):\n    print(kwargs)\n\nadd(1, 2, 3, 4, 5)\n\nsub(a=1, b=2, c=3)\n\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nsub(**my_dict)\n</code></pre>"},{"location":"01-basics/02-data-structures/00-loops-and-functions/#controlling-function-arguments-with-and","title":"\ud83d\ude80 Controlling Function Arguments with <code>*</code> and <code>/</code>","text":"<p>What are <code>*</code> and <code>/</code>?</p> <ul> <li><code>/</code> (Positional-Only Arguments):<ul> <li>Arguments before / must be passed positionally (not as keyword arguments).</li> </ul> </li> <li><code>*</code> (Keyword-Only Arguments):<ul> <li>Arguments after * must be passed as keyword arguments.</li> </ul> </li> </ul> <pre><code>def func(a, b, /, c, d):\n    print(a, b, c, d)\n\nfunc(1, 2, c=3, d=4)  # \u2705 Works\nfunc(a=1, b=2, c=3, d=4)  # \u274c Error: a and b must be positional\n\n# ===============================\n\ndef func(a, b, *, c, d):\n    print(a, b, c, d)\n\nfunc(1, 2, c=3, d=4)  # \u2705 Works\nfunc(1, 2, 3, 4)  # \u274c Error: c and d must be keyword arguments\n\n# ===============================\n\ndef configure(x, y, /, z, *, verbose=False):\n    print(f\"x: {x}, y: {y}, z: {z}, verbose: {verbose}\")\n\nconfigure(1, 2, 3, verbose=True)  # \u2705 Works\nconfigure(1, 2, z=3, verbose=True)  # \u2705 Works\nconfigure(x=1, y=2, z=3, verbose=True)  # \u274c Error: x and y must be positional\nconfigure(1, 2, 3, True)  # \u274c Error: verbose must be keyword-only\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/","title":"Lists &amp; Tuples","text":""},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#lists","title":"Lists","text":"<p>Lists are mutable ordered sequences.</p> <ul> <li>Creating Lists</li> </ul> <pre><code>lst = [1, 2, 3, 4, 5]\nempty_lst = []\nlist_from_tuple = list((1, 2, 3))\nlist_from_range = list(range(5))\n</code></pre> <ul> <li>Lists: Accessing Elements</li> </ul> <pre><code>first = lst[0]      # First element\nlast = lst[-1]      # Last element\nsublist = lst[1:4]  # Slicing (index 1 to 3)\n</code></pre> <ul> <li>Modifying Lists</li> </ul> <pre><code>lst.append(6)       # Add an element\nlst.insert(2, 99)   # Insert at index 2\nlst.extend([7, 8])  # Extend list\nlst[0] = 0          # Modify element\nlst.remove(3)       # Remove element by value\ndel lst[1]          # Delete by index\n</code></pre> <ul> <li>Sorting &amp; Reversing</li> </ul> <pre><code>lst.sort()          # Sort in ascending order\nlst.sort(reverse=True) # Sort in descending order\nlst.reverse()       # Reverse list in place\nsorted_lst = sorted(lst) # Returns sorted list without modifying original\n</code></pre> <ul> <li>Length &amp; Membership</li> </ul> <pre><code>length = len(lst)       # Get length\nexists = 3 in lst       # Check membership\n</code></pre> <ul> <li>List Comprehensions</li> </ul> <pre><code>squares = [x**2 for x in range(10)]\neven_nums = [x for x in lst if x % 2 == 0]\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#performance-consideration-for-lists","title":"Performance Consideration for lists","text":"<ul> <li>Lists consume more memory due to their dynamic nature.</li> <li>Slower compared to tuples in iteration.</li> <li>Appending (<code>.append()</code>) is faster than inserting (<code>.insert()</code>).</li> </ul>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#tuples","title":"Tuples","text":"<p>Tuples are immutable ordered sequences.</p> <ul> <li>Creating Tuples</li> </ul> <pre><code>tpl = (1, 2, 3, 4, 5)\nsingle_element_tpl = (42,)  # Comma needed for single element\ntuple_from_list = tuple([1, 2, 3])\n</code></pre> <ul> <li>Tuples: Accessing Elements</li> </ul> <pre><code>first = tpl[0]      # First element\nlast = tpl[-1]      # Last element\nsubtuple = tpl[1:4] # Slicing\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#named-tuples","title":"Named Tuples","text":"<p>Useful for struct-like behavior.</p> <pre><code>from collections import namedtuple\n\nPoint = namedtuple('Point', ['x', 'y'])\np = Point(10, 20)\nprint(p.x, p.y)  # Accessing named attributes\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#named-tuples-with-classes","title":"Named tuples with classes","text":"<pre><code>from typing import NamedTuple\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\np = Point(10, 20)\nprint(p.x, p.y)  # Accessing named attributes\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#tuple-methods","title":"Tuple methods","text":"<ul> <li><code>_asdict()</code>: Convert to a dictionary.</li> <li><code>_make()</code>: Convert a sequence or iterable to a tuple.</li> <li><code>_replace()</code>: Return a new tuple with replaced values.</li> <li><code>_fields()</code>: Get field names.</li> <li><code>_field_defaults()</code>: Get field defaults.</li> </ul> <pre><code>from collections import namedtuple\n\nPoint = namedtuple('Point', ['x', 'y'], defaults=[0])\np = Point(10, 20)\n\nprint(p._asdict())\nprint(p._make([1, 2]))\nprint(p._replace(x=100))\nprint(p._fields)\nprint(p._field_defaults)\n</code></pre>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#performance-consideration-for-tuples","title":"Performance Consideration for tuples","text":"<ul> <li>Tuples use less memory than lists.</li> <li>Faster than lists in iteration and lookup.</li> <li>Immutable, which makes them hashable (can be used as dict keys).</li> </ul>"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#when-to-use-what","title":"When to Use What?","text":"Feature List Tuple Mutability Mutable Immutable Performance Slower Faster Memory Usage More Less Use Case Dynamic Data Fixed Data"},{"location":"01-basics/02-data-structures/01-lists-and-tuples/#quick-functions-reference","title":"Quick Functions Reference","text":"Operation List Tuple Length <code>len(lst)</code> <code>len(tpl)</code> Sort <code>lst.sort()</code> for inplace; <code>sorted(lst)</code> returns new list <code>sorted(tpl)</code> Reverse <code>lst.reverse()</code> <code>reversed(tpl)</code> Append <code>lst.append(x)</code> \u274c (Immutable) Insert <code>lst.insert(i, x)</code> \u274c (Immutable) Remove <code>lst.remove(x)</code> \u274c (Immutable) Membership <code>x in lst</code> <code>x in tpl</code>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/","title":"Dictionaries &amp; Sets in Python","text":""},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#dictionaries","title":"Dictionaries","text":"<p>Dictionaries store key-value pairs and are mutable.</p>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#creating-dictionaries","title":"Creating Dictionaries","text":"<pre><code>dct = {'a': 1, 'b': 2, 'c': 3}\nempty_dct = {}\ndict_from_pairs = dict([('a', 1), ('b', 2)])\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#accessing-modifying","title":"Accessing &amp; Modifying","text":"<pre><code>value = dct['a']           # Access value\ndct['d'] = 4              # Add new key-value pair\ndct['a'] = 10             # Modify value\ndel dct['b']              # Delete key-value pair\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#dictionary-methods","title":"Dictionary Methods","text":"<pre><code>keys = dct.keys()          # Get all keys\nvalues = dct.values()      # Get all values\nitems = dct.items()        # Get key-value pairs\ndefault = dct.get('x', 0)  # Get with default\n\n# loop through dict\nfor key, value in dct.items():\n    print(key, value)\n\n# check if key exists in dict\nif 'x' in dct:\n    print(dct['x'])\nelse:\n    print('x not found')\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#defaultdict","title":"DefaultDict","text":"<p>A <code>defaultdict</code> provides default values for missing keys.</p> <pre><code>from collections import defaultdict\ndd = defaultdict(int)  # Default value is 0\ndd['x'] += 1          # Works without key error\n\ndl = defaultdict(list)\ndl['x'].append(1) # Works without key error, creates empty list\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#ordereddict","title":"OrderedDict","text":"<p>An <code>OrderedDict</code> remembers the order of items.</p> <pre><code># A Python program to demonstrate working of OrderedDict\nfrom collections import OrderedDict\n\nod = OrderedDict()\nod['a'] = 1\nod['b'] = 2\nod['c'] = 3\nod['d'] = 4\nod['a'] = 5\n\nfor key, value in od.items():\n    print(key, value)\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#equality-in-ordered-dict","title":"Equality in ordered dict","text":"<pre><code>from collections import OrderedDict\n\n# Create two ordered dictionaries with different orderings\nod1 = OrderedDict([('a', 1), ('b', 2), ('c', 3)])\nod2 = OrderedDict([('c', 3), ('b', 2), ('a', 1)])\n\n# Compare the ordered dictionaries for equality\nprint(od1 == od2) # False\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#sets","title":"Sets","text":"<p>Sets store unique elements and are unordered.</p>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#creating-sets","title":"Creating Sets","text":"<pre><code>s = {1, 2, 3, 4, 5}\nempty_set = set()\nset_from_list = set([1, 2, 3, 2, 1])  # Removes duplicates\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#set-operations","title":"Set Operations","text":"<pre><code>s.add(6)            # Add an element\ns.remove(3)         # Remove an element\nunion = s | {7, 8}  # Union\nintersection = s &amp; {2, 4, 6}  # Intersection\ndifference = s - {1, 2}  # Difference\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#membership-length","title":"Membership &amp; Length","text":"<pre><code>length = len(s)     # Get length\nexists = 3 in s     # Check membership\n\n# loop through set\nfor element in s:\n    print(element)\n</code></pre> <p>int v/s tuple v/s set</p> <pre><code>v1 = (1) # int\nv2 = (1,) # tuple\nv3 = {1} # set\n</code></pre>"},{"location":"01-basics/02-data-structures/02-sets-and-dicts/#quick-functions-reference","title":"Quick Functions Reference","text":"Operation Dictionary Set Length <code>len(dct)</code> <code>len(s)</code> Access Value <code>dct[key]</code> \u274c Add Item <code>dct[key] = value</code> <code>s.add(x)</code> Remove Item <code>del dct[key]</code> <code>s.remove(x)</code> Membership <code>key in dct</code> <code>x in s</code> Union \u274c <code>s | other_set</code> Intersection \u274c <code>s &amp; other_set</code> Difference \u274c <code>s - other_set</code>"},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/","title":"Map, Filter, Reduce and Lambda","text":""},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/#map","title":"Map","text":"<ul> <li><code>map</code> applies a function to all the items in an input list, and returns new list.</li> </ul> <pre><code>def double(x):\n    return x * 2\n\nnumbers = [1, 2, 3, 4, 5]\ndoubles = list(map(double, numbers))\nprint(doubles)  # [2, 4, 6, 8, 10]\n</code></pre>"},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/#filter","title":"Filter","text":"<ul> <li><code>filter</code> creates a list of elements for which a function returns <code>True</code>.</li> </ul> <pre><code>def is_even(x):\n    return x % 2 == 0\n\nnumbers = [1, 2, 3, 4, 5]\nevens = list(filter(is_even, numbers))\nprint(evens)  # [2, 4]\n</code></pre>"},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/#reduce","title":"Reduce","text":"<ul> <li><code>reduce</code> applies a rolling computation to sequential pairs of values in a list.</li> </ul> <pre><code>from functools import reduce\n\ndef add(x, y):\n    return x + y\n\nnumbers = [1, 2, 3, 4, 5]\nsum = reduce(add, numbers)\nprint(sum)  # 15\n</code></pre>"},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/#lambda","title":"Lambda","text":"<ul> <li><code>lambda</code> is an anonymous function that can have any number of arguments, but can have only one expression.</li> </ul> <pre><code>double = lambda x: x * 2\nprint(double(5))  # 10\n</code></pre>"},{"location":"01-basics/02-data-structures/03-map-filter-reduce-lambda/#using-lambda-function-with-map","title":"Using lambda function with map","text":"<pre><code>numbers = [1, 2, 3, 4, 5]\ndoubles = list(map(lambda x: x * 2, numbers))\nprint(doubles)  # [2, 4, 6, 8, 10]\n</code></pre>"},{"location":"01-basics/02-data-structures/04-queues/","title":"Queues","text":"<p>Info</p> <ul> <li>The queue module implements <code>multi-producer, multi-consumer</code> queues.</li> <li>It is especially <code>useful in threaded programming when information must be exchanged safely between multiple threads</code>.</li> </ul>"},{"location":"01-basics/02-data-structures/04-queues/#queue-types","title":"Queue types","text":"<ul> <li><code>class queue.Queue(maxsize=0)</code></li> </ul> <p>Constructor for a FIFO queue. maxsize is an integer that sets the upperbound limit on the number of items that can be placed in the queue. Insertion will block once this size has been reached, until queue items are consumed. If maxsize is less than or equal to zero, the queue size is infinite.</p> <ul> <li><code>class queue.LifoQueue(maxsize=0)</code></li> </ul> <p>Constructor for a LIFO queue. maxsize is an integer that sets the upperbound limit on the number of items that can be placed in the queue. Insertion will block once this size has been reached, until queue items are consumed. If maxsize is less than or equal to zero, the queue size is infinite.</p> <ul> <li><code>class queue.PriorityQueue(maxsize=0)</code></li> </ul> <p>Constructor for a priority queue. maxsize is an integer that sets the upperbound limit on the number of items that can be placed in the queue. Insertion will block once this size has been reached, until queue items are consumed. If maxsize is less than or equal to zero, the queue size is infinite.</p> <p>The lowest valued entries are retrieved first (the lowest valued entry is the one that would be returned by min(entries)). A typical pattern for entries is a tuple in the form: (priority_number, data).</p> <p>If the data elements are not comparable, the data can be wrapped in a class that ignores the data item and only compares the priority number:</p>"},{"location":"01-basics/02-data-structures/04-queues/#queue-methods","title":"Queue methods","text":"<ul> <li><code>q.put(item[, block[, timeout]])</code></li> <li><code>q.get([block[, timeout]])</code></li> <li><code>q.qsize()</code></li> <li><code>q.empty()</code></li> <li><code>q.full()</code></li> <li><code>q.shutdown()</code> - signal the queue that no more items will be added</li> <li><code>q.put_nowait(item)</code> (alias for <code>q.put(item, False)</code>) - don't block, if queue is empty, raise <code>exception: queue.Full</code></li> <li><code>q.get_nowait()</code> (alias for <code>q.get(False)</code>) - don't block, if queue is empty, raise <code>exception: queue.Empty</code></li> <li><code>q.join()</code> - block until all items in the queue are processed (queue is empty)</li> </ul>"},{"location":"01-basics/02-data-structures/04-queues/#example","title":"Example","text":"<pre><code>import threading\nimport queue\n\nq = queue.Queue()\n\ndef worker():\n    while True:\n        item = q.get()\n        print(f'Working on {item}')\n        print(f'Finished {item}')\n        q.task_done()\n\n# Turn-on the worker thread.\nthreading.Thread(target=worker, daemon=True).start()\n\n# Send thirty task requests to the worker.\nfor item in range(30):\n    q.put(item)\n\n# Block until all tasks are done.\nq.join()\nprint('All work completed')\n</code></pre>"},{"location":"01-basics/02-data-structures/04-queues/#multiprocessing-queue","title":"MultiProcessing Queue","text":"<ul> <li>Queue from <code>import queue</code> is thread-safe, but not multiprocessing-safe.</li> <li>For multiprocessing, use <code>multiprocessing.Queue</code></li> </ul> <pre><code>from multiprocessing import Process, Queue\n\ndef f(q):\n    q.put([42, None, 'hello'])\n\nif __name__ == '__main__':\n    q = Queue()\n    p = Process(target=f, args=(q,))\n    p.start()\n    print(q.get())    # prints \"[42, None, 'hello']\"\n    p.join()\n</code></pre>"},{"location":"01-basics/02-data-structures/04-queues/#deque","title":"DeQue","text":"<ul> <li><code>class collections.deque([iterable[, maxlen]])</code></li> <li><code>Deque</code> are thread-safe, but not multiprocessing-safe.</li> </ul> <p>Deque objects are like stacks or FIFO queues, as they support adding and removing elements from both ends.</p> <ul> <li><code>deque.append(x)</code> - add x to the right side of the deque</li> <li><code>deque.appendleft(x)</code> - add x to the left side of the deque</li> <li><code>deque.pop()</code> - remove and return an element from the right side of the deque</li> <li><code>deque.popleft()</code> - remove and return an element from the left side of the deque</li> <li><code>deque.clear()</code> - remove all elements from the deque</li> <li><code>deque.count(x)</code> - count the number of occurrences of x in the deque</li> <li><code>deque.extend(iterable)</code> - extend the right side of the deque by appending elements from the iterable</li> <li><code>deque.extendleft(iterable)</code> - extend the left side of the deque by appending elements from the iterable</li> <li><code>deque.rotate(n)</code> - rotate the deque n steps to the right</li> </ul> <pre><code>from collections import deque\nd = deque('ghi')                 # make a new deque with three items\nfor elem in d:                   # iterate over the deque's elements\n    print(elem.upper())\n\nd.append('j')                    # add a new entry to the right side\nd.appendleft('f')                # add a new entry to the left side\nd                                # show the representation of the deque\n\nd.pop()                          # return and remove the rightmost item\n\nd.popleft()                      # return and remove the leftmost item\n\nlist(d)                          # list the contents of the deque\n\nd[0]                             # peek at leftmost item\n\nd[-1]                            # peek at rightmost item\n\nlist(reversed(d))                # list the contents of a deque in reverse\n\n'h' in d                         # search the deque\n\nd.extend('jkl')                  # add multiple elements at once\nd\n\nd.rotate(1)                      # right rotation\nd\n\nd.rotate(-1)                     # left rotation\nd\n\ndeque(reversed(d))               # make a new deque in reverse order\n\nd.clear()                        # empty the deque\nd.pop()                          # cannot pop from an empty deque\n\nd.extendleft('abc')              # extendleft() reverses the input order\nd\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/","title":"Contextlib","text":"<ul> <li>provides utilities for common tasks involving the <code>with statement</code>.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#what-it-provides","title":"What it provides?","text":"<ul> <li>contextmanager</li> <li>asynccontextmanager</li> <li>closing</li> <li>aclosing</li> <li>nullcontext</li> <li>suppress</li> <li>redirect_stdout</li> <li>redirect_stderr</li> <li>chdir</li> <li>ContextDecorator</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#implementing-a-simple-context-manager-using-class","title":"Implementing a simple Context Manager (using <code>class</code>)","text":"<ul> <li> <p>A class needs to implement <code>__enter__</code> and <code>__exit__</code> methods to be used as a context manager.</p> </li> <li> <p><code>__enter__</code> method is called when the <code>with</code> block is entered. It doesn't take any arguments.</p> </li> <li><code>__exit__</code> method is called when the <code>with</code> block is exited. It takes three arguments:<ul> <li><code>exc_type</code>: exception type</li> <li><code>exc_value</code>: exception value</li> <li><code>traceback</code>: traceback object</li> </ul> </li> <li>If no exception occurs, all three arguments are <code>None</code>. Else, they contain the exception details.</li> </ul> <pre><code>class MyCtx:\n    def __init__(self, num):\n        self.num = num\n\n    def __enter__(self):\n        print(\"enter block executing\")\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"exit block executing\")\n\n\nif __name__ == \"__main__\":\n    with MyCtx(4) as c:\n        print(f\"value of {c.num=}\")\n\n    print(\"-\"*40)\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#contextmanager-decorator","title":"<code>contextmanager</code> decorator","text":"<ul> <li>A simpler way to create a context manager is to use the <code>contextmanager</code> decorator from the <code>contextlib</code> module.</li> <li>You don't need to implement a whole new class just to be able to use <code>with statements</code> with it.</li> <li><code>function decorated with @contextmanager</code> should <code>yield</code> the resource that needs to be managed.</li> <li>Use try, except and finally blocks.</li> <li><code>exception</code> raised inside the <code>with block</code> can be caught in the <code>except block</code>.</li> <li><code>finally block</code> is used to clean up the resource, after the <code>with block</code> is exited.</li> </ul> <pre><code>from contextlib import contextmanager\n\n@contextmanager\ndef my_ctx(*args, **kwargs):\n    try:\n        print('Entering context')\n        yield 'hello'\n    except Exception as e:\n        print(f'Caught exception: {e}')\n    finally:\n        print('Exiting context')\n\nif __name__ == '__main__':\n    with my_ctx() as val:\n        print(f'Value: {val}')\n    print(\"-\"*50)\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#asynccontextmanager","title":"AsyncContextManager","text":"<ul> <li>similar to <code>contextmanager</code>, but for <code>async</code> functions.</li> <li>Used with <code>async with</code> statements.</li> <li>To implement, use <code>__aenter__</code> and <code>__aexit__</code> methods.</li> </ul> <pre><code>from contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def get_connection():\n    conn = await acquire_db_connection()\n    try:\n        yield conn\n    finally:\n        await release_db_connection(conn)\n\nasync def get_all_users():\n    async with get_connection() as conn:\n        return conn.query('SELECT ...')\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#closing","title":"Closing","text":"<ul> <li>closing is a helper function that simplifies the use of resources that need to be closed properly, such as files, sockets, or database connections.</li> <li>It ensures that the resource gets closed automatically when you're done with it, even if an error occurs.</li> </ul> <p>Why Use closing?</p> <ul> <li>Some objects don't support the with statement directly (they don't have a <code>__enter__</code> or <code>__exit__</code> method).</li> <li>The closing function makes it possible to use these objects in a with block, ensuring proper cleanup.</li> <li>When the block ends, closing calls the resource's <code>close() method</code> automatically</li> </ul> <pre><code>from contextlib import contextmanager, closing\n\nclass MyCtx:\n    def __init__(self, name):\n        self.name = name\n        print(\"myctx function called\")\n    def close(self):\n        print(\"myctx close function called\")\n\n\nif __name__ == \"__main__\":\n    with closing(MyCtx(\"deependu\")) as m:\n        print(m.name)\n</code></pre> <p>expected Output:</p> <pre><code>myctx function called\ndeependu\nmyctx close function called\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#aclosing","title":"Aclosing","text":"<ul> <li><code>aclosing</code> is the async version of <code>closing</code>.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#nullcontext","title":"NullContext","text":"<ul> <li><code>do-nothing</code> placeholder that can be used with <code>with statement</code>.</li> <li>Used when you don't need to do anything in the <code>__enter__</code> and <code>__exit__</code> methods.</li> <li>Mostly used for maintaining consistency in the code.</li> <li>Whatever a function returns, it should return support <code>with</code> statement.</li> </ul> <pre><code>def myfunction(arg, ignore_exceptions=False):\n    if ignore_exceptions:\n        # Use suppress to ignore all exceptions.\n        cm = contextlib.suppress(Exception)\n    else:\n        # Do not ignore any exceptions, cm has no effect.\n        cm = contextlib.nullcontext()\n    with cm:\n        # Do something\n</code></pre> <ul> <li>in the above code, we wanted to use <code>with block</code>, so we used <code>nullcontext</code> to maintain consistency.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#suppress","title":"Suppress","text":"<ul> <li>Return a context manager that suppresses any of the specified exceptions if they occur in the body of a with statement and then resumes execution with the first statement following the end of the with statement.</li> </ul> <pre><code>from contextlib import suppress\n\nwith suppress(FileNotFoundError):\n    os.remove('somefile.tmp')\n\n## equivalent to\n# try:\n#     os.remove('somefile.tmp')\n# except FileNotFoundError:\n#     pass\n</code></pre> <ul> <li>To pass multiple exceptions, use a tuple.</li> </ul> <pre><code>from contextlib import suppress\n\nif __name__ == \"__main__\":\n    with suppress((ValueError, FileNotFoundError)):\n        raise ValueError()\n        raise FileNotFoundError()\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#redirect_stdout","title":"Redirect_stdout","text":"<ul> <li>Instead of printing to the console, you can redirect the output to a file or a string.</li> <li>To do this, we can modify the <code>sys.stdout</code> object to point to a different file or string.</li> </ul> <pre><code>import sys\n\nsys.stdout = open('output.txt', 'w')\nprint('This is redirected to a file')\n</code></pre> <ul> <li>But, this is not a good practice, as it can lead to issues with other parts of the code that rely on <code>sys.stdout</code>, if we forget to reset it back to the original value.</li> <li><code>redirect_stdout</code> provides a context manager that temporarily redirects <code>sys.stdout</code> to a different file or stream.</li> </ul> <pre><code>from contextlib import redirect_stdout\n\nwith open('output.txt', 'w') as f:\n    with redirect_stdout(f):\n        print('This is redirected to a file')\n\nprint('This is printed to the console')\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#redirect_stderr","title":"Redirect_stderr","text":"<ul> <li>Similar to <code>redirect_stdout</code>, but for <code>sys.stderr</code>.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#chdir","title":"chdir","text":"<ul> <li>This is a simple wrapper around chdir(), it <code>changes the current working directory upon entering and restores the old one on exit</code>.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#contextdecorator","title":"ContextDecorator","text":"<ul> <li>Used to <code>create custom decorators</code> that can be <code>used as context managers</code>.</li> <li><code>@contextmanager</code> is implemented using the same method.</li> <li>Class inheriting from <code>ContextDecorator</code> have to implement <code>__enter__</code> and <code>__exit__</code> as normal.</li> </ul> <pre><code>from contextlib import ContextDecorator\n\nclass mycontext(ContextDecorator):\n    def __enter__(self):\n        print('Starting')\n        return self\n\n    def __exit__(self, *exc):\n        print('Finishing')\n        return False\n\n# =============\n@mycontext()\ndef function():\n    print('The bit in the middle')\n\nfunction()\n# output:   Starting\n#           The bit in the middle\n#           Finishing\n\nwith mycontext():\n    print('The bit in the middle')\n\n# output:   Starting\n#           The bit in the middle\n#           Finishing\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#how-are-they-implemented","title":"How are they implemented?","text":""},{"location":"01-basics/03-core-python-libraries/01-contextlib/#nullcontext_1","title":"nullcontext","text":"<pre><code>class MyNullcontext:\n    def __enter__(self):\n        return None\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        pass\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/01-contextlib/#closing_1","title":"closing","text":"<pre><code>class MyClosing:\n    def __enter__(self, some_resource):\n        return some_resource\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        some_resource.close() # just calls the `close` method of the resource\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/02-atexit/","title":"AtExit (<code>atexit</code>) Module","text":"<p>The <code>atexit</code> module in Python allows you to register functions that will run automatically when the program is about to exit.</p> <ul> <li>This is useful for performing cleanup tasks like closing files, releasing resources, or printing goodbye messages.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#basic-usage-of-atexit","title":"Basic Usage of <code>atexit</code>","text":"<ul> <li> <p>Registering Functions:     Use <code>atexit.register(function_name)</code> to register a function that will be called upon program termination.</p> </li> <li> <p>Automatic Execution:     Registered functions are executed in the reverse order of their registration when the program exits normally (no crashes or <code>os._exit</code>).</p> </li> <li> <p>Unregistering Functions:     You can unregister a function using <code>atexit.unregister(function_name)</code>.</p> </li> </ul>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#registering-a-function","title":"Registering a Function","text":"<pre><code>import atexit\n\ndef goodbye():\n    print(\"Program is exiting... Goodbye!\")\n\n# Register the function\natexit.register(goodbye)\n\n# Program logic\nprint(\"Hello, World!\")\n</code></pre> <p>Output:</p> <pre><code>Hello, World!\nProgram is exiting... Goodbye!\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#multiple-registered-functions","title":"Multiple Registered Functions","text":"<pre><code>import atexit\n\ndef func1():\n    print(\"First cleanup function.\")\n\ndef func2():\n    print(\"Second cleanup function.\")\n\n# Register both functions\natexit.register(func1)\natexit.register(func2)\n\nprint(\"Program is running...\")\n</code></pre> <p>Output:</p> <pre><code>Program is running...\nSecond cleanup function.\nFirst cleanup function.\n</code></pre> <p>Note: Functions are called in reverse order of their registration (<code>func2</code> runs before <code>func1</code>).</p>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#passing-arguments-to-functions","title":"Passing Arguments to Functions","text":"<p>You can use <code>atexit.register</code> with additional arguments:</p> <pre><code>import atexit\n\ndef greet(name):\n    print(f\"Goodbye, {name}!\")\n\n# Register with arguments\natexit.register(greet, \"Alice\")\n\nprint(\"Program is running...\")\n</code></pre> <p>Output:</p> <pre><code>Program is running...\nGoodbye, Alice!\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#using-lambda-functions","title":"Using <code>lambda</code> Functions","text":"<p>You can register anonymous functions with <code>lambda</code>:</p> <pre><code>import atexit\n\natexit.register(lambda: print(\"Lambda function executed!\"))\n\nprint(\"Program is running...\")\n</code></pre> <p>Output:</p> <pre><code>Program is running...\nLambda function executed!\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#atexit-decorator","title":"<code>atexit</code> decorator","text":"<pre><code>import atexit\n\n@atexit.register\ndef goodbye():\n    print('You are now leaving the Python sector.')\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#key-points-to-remember","title":"Key Points to Remember","text":"<ol> <li> <p>Normal Exit Only: Functions registered with <code>atexit</code> are executed only during a normal exit (not if the program crashes or <code>os._exit()</code> is called).</p> </li> <li> <p>Reverse Execution: Functions are executed in reverse order of their registration.</p> </li> <li> <p>Use Cases: Cleanup tasks, logging program termination, closing open resources.</p> </li> </ol>"},{"location":"01-basics/03-core-python-libraries/02-atexit/#summary","title":"Summary","text":"<ul> <li>The <code>atexit</code> module is a handy way to manage cleanup tasks when your program exits.</li> <li>By registering functions with <code>atexit.register</code>, you ensure they run automatically at termination.</li> <li>It\u2019s particularly useful for tasks like saving state, closing connections, or releasing resources.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/03-signal/","title":"Signal module","text":"<ul> <li>The <code>signal</code> module in Python provides a way to handle system signals, allowing you to execute custom code when specific signals are received by your program.</li> <li>Signals are asynchronous notifications sent to a process, often triggered by external events or user actions (e.g., pressing <code>Ctrl+C</code>).</li> </ul>"},{"location":"01-basics/03-core-python-libraries/03-signal/#basic-usage","title":"Basic Usage","text":"<p>Signals</p> <ul> <li>Signals are identified by constants like <code>signal.SIGINT</code>, <code>signal.SIGTERM</code>, etc.</li> <li><code>SIGINT</code> is sent when you press <code>Ctrl+C</code>.</li> <li><code>SIGTERM</code> is sent to terminate a program (e.g., via <code>kill</code> command).</li> </ul> <p>Handlers</p> <ul> <li>You can register a custom function (signal handler) to be executed when a specific signal is received.</li> <li>Use <code>signal.signal(signal_name, handler_function)</code> to register a handler.</li> </ul>"},{"location":"01-basics/03-core-python-libraries/03-signal/#handling-sigint-ctrlc","title":"Handling <code>SIGINT</code> (Ctrl+C)","text":"<pre><code>import signal\nimport time\n\ndef handle_sigint(signum, frame):\n    print(f\"Received signal {signum}. Exiting gracefully!\")\n    exit(0)\n\n# Register the handler for SIGINT\nsignal.signal(signal.SIGINT, handle_sigint)\n\nprint(\"Running program. Press Ctrl+C to interrupt.\")\nwhile True:\n    time.sleep(1)\n</code></pre> <p>Output when you press <code>Ctrl+C</code>:</p> <pre><code>Running program. Press Ctrl+C to interrupt.\nReceived signal 2. Exiting gracefully!\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/03-signal/#handling-sigterm","title":"Handling <code>SIGTERM</code>","text":"<pre><code>import signal\nimport time\n\ndef handle_sigterm(signum, frame):\n    print(\"Received SIGTERM. Cleaning up resources...\")\n    exit(0)\n\n# Register the handler for SIGTERM\nsignal.signal(signal.SIGTERM, handle_sigterm)\n\nprint(\"Running program. Use 'kill -15 &lt;PID&gt;' to terminate.\")\nwhile True:\n    time.sleep(1)\n</code></pre> <p>Output when sending <code>SIGTERM</code>:</p> <pre><code>Received SIGTERM. Cleaning up resources...\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/03-signal/#ignoring-signals","title":"Ignoring Signals","text":"<p>You can ignore specific signals by setting their handler to <code>signal.SIG_IGN</code>:</p> <pre><code>import signal\nimport time\n\n# Ignore SIGINT (Ctrl+C)\nsignal.signal(signal.SIGINT, signal.SIG_IGN)\n\nprint(\"Try pressing Ctrl+C. It will be ignored.\")\ntime.sleep(10)\nprint(\"Program finished.\")\n</code></pre> <p>Output:</p> <pre><code>Try pressing Ctrl+C. It will be ignored.\nProgram finished.\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/03-signal/#restoring-default-behavior","title":"Restoring Default Behavior","text":"<p>You can restore the default behavior for a signal using <code>signal.SIG_DFL</code>:</p> <pre><code>import signal\nimport time\n\ndef custom_handler(signum, frame):\n    print(\"Custom handler for SIGINT!\")\n\n# Set custom handler\nsignal.signal(signal.SIGINT, custom_handler)\n\nprint(\"Press Ctrl+C to trigger the custom handler.\")\ntime.sleep(5)\n\n# Restore default behavior\nsignal.signal(signal.SIGINT, signal.SIG_DFL)\nprint(\"Default behavior restored. Press Ctrl+C again.\")\ntime.sleep(5)\n</code></pre> <p>Output:</p> <pre><code>Press Ctrl+C to trigger the custom handler.\nCustom handler for SIGINT!\nDefault behavior restored. Press Ctrl+C again.\n# Exits program on second Ctrl+C\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/03-signal/#using-signalalarm","title":"Using <code>signal.alarm</code>","text":"<p>You can set an alarm to send a <code>SIGALRM</code> signal after a specific time:</p> <pre><code>import signal\nimport time\n\ndef handle_alarm(signum, frame):\n    print(\"Alarm triggered!\")\n\n# Register handler and set alarm\nsignal.signal(signal.SIGALRM, handle_alarm)\nsignal.alarm(5)  # Trigger SIGALRM after 5 seconds\n\nprint(\"Waiting for alarm...\")\ntime.sleep(10)\n</code></pre> <p>Output after 5 seconds:</p> <pre><code>Waiting for alarm...\nAlarm triggered!\n</code></pre>"},{"location":"01-basics/03-core-python-libraries/03-signal/#key-points-to-remember","title":"Key Points to Remember","text":"<ol> <li> <p>Signals</p> <p>Signals are used for asynchronous events like interrupts or termination requests.</p> </li> <li> <p>Handlers</p> <p>Register handlers using <code>signal.signal(signal_name, handler_function)</code>.</p> <p>Handlers must accept two arguments: <code>signum</code> (signal number) and <code>frame</code> (current stack frame).</p> </li> <li> <p>Special Constants</p> <p><code>signal.SIG_IGN</code>: Ignore the signal.</p> <p><code>signal.SIG_DFL</code>: Restore the default behavior.</p> </li> <li> <p>Common Signals</p> <p><code>SIGINT</code>: Interrupt (Ctrl+C).</p> <p><code>SIGTERM</code>: Termination request.</p> <p><code>SIGALRM</code>: Alarm timer expiration.</p> </li> </ol>"},{"location":"01-basics/03-core-python-libraries/03-signal/#summary","title":"Summary","text":"<ul> <li>The <code>signal</code> module provides fine-grained control over how your Python program responds to external signals.</li> <li>You can customize behavior for interrupts (<code>Ctrl+C</code>), termination requests, or other signals, making it ideal for building robust, interactive, and cleanup-aware applications.</li> </ul>"},{"location":"01-basics/04-features/01-iterators/","title":"Iterators","text":"<ul> <li>Anything that can be done with generators can also be done with class-based iterators.</li> <li>What makes generators so compact is that the <code>__iter__()</code> and <code>__next__()</code> methods are created automatically.</li> </ul>"},{"location":"01-basics/04-features/01-iterators/#overview","title":"Overview","text":"<ul> <li>When we write <code>for</code> loop, it internally calls <code>iter()</code> on the container object.</li> <li>The <code>iter()</code> function returns an <code>iterator</code> object.</li> <li>The <code>iterator</code> object has a <code>__next__()</code> method that returns the next item in the container.</li> <li>The <code>__next__()</code> method is called repeatedly until it raises <code>StopIteration</code> exception, which tells the <code>for</code> loop to stop iterating.</li> </ul> <pre><code>&gt;&gt;&gt; s = 'abc'\n&gt;&gt;&gt; it = iter(s)\n&gt;&gt;&gt; it\n&lt;str_iterator object at 0x10c90e650&gt;\n&gt;&gt;&gt; next(it)\n'a'\n&gt;&gt;&gt; next(it)\n'b'\n&gt;&gt;&gt; next(it)\n'c'\n&gt;&gt;&gt; next(it)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n    next(it)\nStopIteration\n</code></pre>"},{"location":"01-basics/04-features/01-iterators/#code","title":"Code","text":"<pre><code>class Reverse:\n    \"\"\"Iterator for looping over a sequence backwards.\"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.index = len(data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index &lt;= 0:\n            raise StopIteration\n        self.index = self.index - 1\n        return self.data[self.index]\n\nrev = Reverse('abcdef')\n\nfor c in rev:\n    print(c)\n</code></pre>"},{"location":"01-basics/04-features/02-generators/","title":"Generators","text":""},{"location":"01-basics/04-features/02-generators/#overview","title":"Overview","text":"<ul> <li><code>Generators</code> are a simple and powerful tool for creating <code>iterators</code>.</li> <li>They are written like regular functions but use the <code>yield</code> statement whenever they want to return data.</li> <li>Each time <code>next()</code> is called on it, the generator resumes where it left off (it remembers all the data values and which statement was last executed).</li> <li>When it terminates, it raises <code>StopIteration</code> exception.</li> </ul> <pre><code>&gt;&gt;&gt; def reverse(data):\n...    for index in range(len(data)-1, -1, -1):\n...        yield data[index]\n&gt;&gt;&gt;\n&gt;&gt;&gt; for char in reverse('golf'):\n...    print(char)\nf\nl\no\ng\n</code></pre> <ul> <li>Anything that can be done with generators can also be done with class-based iterators as described in the previous section.</li> <li>What makes generators so compact is that the <code>__iter__()</code> and <code>__next__()</code> methods are created automatically.</li> </ul> <ul> <li>List comprehension:</li> </ul> <pre><code>&gt;&gt;&gt; [x**2 for x in range(10)] # list comprehension\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n&gt;&gt;&gt; (x**2 for x in range(10)) # list comprehension\n&lt;generator object &lt;genexpr&gt; at 0x10c90e650&gt;\n</code></pre> <ul> <li>To convert a generator to a list, use the <code>list()</code> function.</li> <li><code>all()</code> and <code>any()</code> functions can be used to check if all or any of the elements in a generator are true.</li> </ul> <pre><code>&gt;&gt;&gt; list((x**2 for x in range(10)))\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n&gt;&gt;&gt; all((x**2&gt;0 for x in range(10)))\nTrue\n</code></pre> <ul> <li> <p><code>all((...generator))</code> and <code>any((...generator))</code> can also be used with <code>all([...list])</code> and <code>any([...list])</code>.</p> </li> <li> <p>But, generators will be more efficient than lists when the condition is more complex and the list is very long.</p> </li> </ul>"},{"location":"01-basics/04-features/02-generators/#code","title":"Code","text":"<pre><code>def fib(n):\n    a, b = 0, 1\n    while n &gt; 0:\n        yield a\n        a, b = b, a + b\n        n -= 1\n\nfib_gen = fib(10)\nprint(f\"{fib_gen=}\")\n\nfor i in fib_gen:\n    print(i)\n</code></pre>"},{"location":"01-basics/04-features/03-indexing/","title":"Indexing feature in Class","text":"<p>To add indexing functionality (like <code>obj[i]</code>) to a Python class, you need to implement the <code>__getitem__</code> method in your class. Optionally, you can also implement <code>__setitem__</code> and <code>__delitem__</code> to handle assignment and deletion of items.</p>"},{"location":"01-basics/04-features/03-indexing/#read-indexing","title":"Read indexing","text":"<pre><code>class MyList:\n    def __init__(self, data):\n        self.data = data  # Store the data in an internal list\n\n    def __getitem__(self, index):\n        return self.data[index]  # Use the internal list's indexing\n\n# Example usage\nobj = MyList([10, 20, 30, 40])\nprint(obj[1])  # Outputs: 20\n</code></pre>"},{"location":"01-basics/04-features/03-indexing/#write-indexing","title":"Write indexing","text":"<pre><code>class MyList:\n    def __init__(self, data):\n        self.data = data\n\n    def __getitem__(self, index):\n        return self.data[index]\n\n    def __setitem__(self, index, value):\n        self.data[index] = value  # Allow modification of the internal list\n\n# Example usage\nobj = MyList([10, 20, 30, 40])\nprint(obj[1])  # Outputs: 20\nobj[1] = 99    # Updates the second element\nprint(obj[1])  # Outputs: 99\n</code></pre>"},{"location":"01-basics/04-features/03-indexing/#deletion-at-index","title":"Deletion at index","text":"<pre><code>class MyList:\n    def __init__(self, data):\n        self.data = data\n\n    def __getitem__(self, index):\n        return self.data[index]\n\n    def __setitem__(self, index, value):\n        self.data[index] = value\n\n    def __delitem__(self, index):\n        del self.data[index]  # Remove the specified element\n\n# Example usage\nobj = MyList([10, 20, 30, 40])\nprint(obj[1])  # Outputs: 20\ndel obj[1]     # Deletes the second element\nprint(obj.data)  # Outputs: [10, 30, 40]\n</code></pre>"},{"location":"01-basics/04-features/03-indexing/#support-for-slicing","title":"Support for Slicing","text":"<pre><code>if isinstance(index, slice):\n    ...\n</code></pre> <p>If you want your class to support slicing (e.g., <code>obj[1:3]</code>), you can handle this in the <code>__getitem__</code>, <code>__setitem__</code>, and <code>__delitem__</code> methods by checking if the <code>index</code> is a slice.</p> <pre><code>class MyList:\n    def __init__(self, data):\n        self.data = data\n\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            print(\"index is a slice\", index)\n        return self.data[index]  # Handles both single index and slicing\n\n    def __setitem__(self, index, value):\n        self.data[index] = value  # Handles both single index and slicing\n\n    def __delitem__(self, index):\n        del self.data[index]  # Handles both single index and slicing\n\n# Example usage\nobj = MyList([10, 20, 30, 40, 50])\nprint(obj[1:4])  # Outputs: [20, 30, 40]\nobj[1:3] = [99, 100]  # Updates a slice\nprint(obj.data)  # Outputs: [10, 99, 100, 40, 50]\n</code></pre>"},{"location":"01-basics/04-features/03-indexing/#summary","title":"Summary","text":"<ol> <li>Implement <code>__getitem__</code> for read-only access (<code>obj[i]</code>).</li> <li>Implement <code>__setitem__</code> for assignment (<code>obj[i] = value</code>).</li> <li>Implement <code>__delitem__</code> for deletion (<code>del obj[i]</code>).</li> <li>Handle slicing by leveraging the fact that <code>index</code> can be a <code>slice</code> object.</li> </ol>"},{"location":"03-concurrency/03-concurrent-executor/","title":"Concurrent.futures in Python","text":"<ul> <li>High level API for asynchronously executing callables</li> <li>Provides:<ul> <li>Base class: Executor</li> <li>ThreadPool Executor</li> <li>ProcessPool Executor</li> </ul> </li> </ul>"},{"location":"03-concurrency/03-concurrent-executor/#executor-class","title":"Executor class","text":"<ul> <li>Executor class is an abstract class that provides methods to execute callables asynchronously</li> <li> <p>It provides two methods:</p> <ul> <li>submit(): Schedules the callable to be executed and returns a Future object</li> <li>map(): Maps the callable to an iterable of callables and returns a generator of Future objects.</li> </ul> </li> <li> <p><code>future</code> object is returned by them. It represents the result of the asynchronous computation.</p> </li> <li><code>map()</code> function's future returns value in the order of the input iterable.</li> <li><code>submit() + as_completed</code> function's future returns value in the order of completion.</li> </ul>"},{"location":"03-concurrency/03-concurrent-executor/#code-example","title":"Code Example","text":"<ul> <li><code>submit() + as_completed()</code></li> </ul> <pre><code>from concurrent.futures import ThreadPoolExecutor, as_completed\nimport time\n\ndef task(n):\n    time.sleep(n)\n    return n * n\n\nif __name__ == \"__main__\":\n    inputs = [3, 1, 4]\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        futures = [executor.submit(task, n) for n in inputs]\n        for future in as_completed(futures):\n            print(future.result())  # Output could be unordered: 1, 9, 16\n</code></pre> <ul> <li><code>map()</code></li> </ul> <pre><code>from concurrent.futures import ThreadPoolExecutor\nimport time\n\ndef task(n):\n    time.sleep(n)  # Simulate variable execution time\n    return n * n\n\nif __name__ == \"__main__\":\n    inputs = [3, 1, 4]\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        results = executor.map(task, inputs)  # Results will be in the order of `inputs`\n\n    for result in results:\n        print(result)  # Output: [9, 1, 16]\n</code></pre>"},{"location":"03-concurrency/04-concurrency-with-queues/","title":"Concurrency with Queues","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\nimport time\nimport threading\nfrom queue import Queue\n\n\ndef task(n: int, q: Queue):\n    print(f\"{n} Task assigned to thread: {threading.current_thread().name}\")\n    time.sleep(n)\n    q.put_nowait(n)\n    return n * n\n\n\ndef process_thread(q: Queue, rm_q: Queue):\n    while True:\n        item = q.get()\n        if item is None:  # Sentinel value to exit\n            break\n        print(f\"processing {item} in thread\")\n        rm_q.put_nowait(item)\n\n\ndef delete_thread(q: Queue):\n    while True:\n        item = q.get()\n        if item is None:  # Sentinel value to exit\n            break\n        print(f\"removing {item} in thread\")\n\n\ndef worker(inputs, num_workers):\n    ready_to_process_queue = Queue()\n    ready_to_delete_queue = Queue()\n\n    t1 = threading.Thread(\n        target=process_thread,\n        name=\"t1\",\n        args=(ready_to_process_queue, ready_to_delete_queue),\n    )\n    t2 = threading.Thread(\n        target=delete_thread, name=\"t2\", args=(ready_to_delete_queue,)\n    )\n\n    t1.start()\n    t2.start()\n\n    print(\"going to start thread pool executor\")\n\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        for n in inputs:\n            executor.submit(task, n, ready_to_process_queue)\n    print(\"all task submitted to thread\")\n    ready_to_process_queue.put_nowait(None)\n    print(\"pushed None to process queue. going to wait for it finish now\")\n    t1.join()\n    # Stop delete_thread **after** processing is complete\n    ready_to_delete_queue.put_nowait(None)\n    t2.join()\n\n\nif __name__ == \"__main__\":\n    inputs = [3, 1, 4, 5, 2]\n    worker(inputs, 3)\n</code></pre>"},{"location":"03-concurrency/05-semaphores/","title":"Semaphores","text":""},{"location":"03-concurrency/05-semaphores/#scenario","title":"Scenario","text":"<p>Imagine 3 workers trying to access a shared resource, but only 2 workers can access it at a time. A semaphore ensures that no more than 2 workers use the resource simultaneously.</p>"},{"location":"03-concurrency/05-semaphores/#multithrading-semaphore","title":"Multithrading semaphore","text":"<pre><code>import threading\nimport time\n\n# Create a semaphore with a max of 2 concurrent accesses\nsemaphore = threading.Semaphore(2)\n\ndef worker(worker_id):\n    print(f\"Worker {worker_id} is waiting to access the resource...\")\n    with semaphore:  # Acquire the semaphore (decrements count)\n        print(f\"Worker {worker_id} acquired access! \ud83d\ude80\")\n        time.sleep(2)  # Simulating work\n        print(f\"Worker {worker_id} released access! \u2705\")\n\n# Create 3 worker threads\nthreads = []\nfor i in range(3):\n    t = threading.Thread(target=worker, args=(i,))\n    threads.append(t)\n    t.start()\n\n# Wait for all threads to finish\nfor t in threads:\n    t.join()\n\nprint(\"All workers finished execution!\")\n</code></pre>"},{"location":"03-concurrency/05-semaphores/#how-it-works","title":"How It Works","text":"<ol> <li>Semaphore(2) \u2192 At most 2 workers can enter the critical section at a time.</li> <li>Each worker waits until the semaphore allows it to proceed.</li> <li>Once inside, the worker \"locks\" the resource, works for 2 seconds, then releases it.</li> <li>New workers enter when a previous worker exits.</li> </ol>"},{"location":"03-concurrency/05-semaphores/#expected-output","title":"Expected Output","text":"<pre><code>Worker 0 is waiting to access the resource...\nWorker 1 is waiting to access the resource...\nWorker 0 acquired access! \ud83d\ude80\nWorker 1 acquired access! \ud83d\ude80\nWorker 2 is waiting to access the resource...\nWorker 0 released access! \u2705\nWorker 2 acquired access! \ud83d\ude80\nWorker 1 released access! \u2705\nWorker 2 released access! \u2705\nAll workers finished execution!\n</code></pre> <ul> <li>Workers 0 and 1 get access first.</li> <li>Worker 2 waits until one of them finishes.</li> <li>When Worker 0 or 1 releases, Worker 2 gets access.</li> </ul>"},{"location":"03-concurrency/05-semaphores/#why-use-this","title":"Why Use This?","text":"<ul> <li>Prevents too many threads from overwhelming a resource.</li> <li>Useful for limiting concurrent database access, API calls, GPU processing, etc.</li> <li>Essential in multiprocessing (like PyTorch <code>DataLoader</code>) to prevent semaphore leaks.</li> </ul> <p>Info</p> <p>Just like threading.Semaphore, we have semaphores for both multiprocessing and async (asyncio).</p>"},{"location":"03-concurrency/05-semaphores/#1-multiprocessing-semaphore","title":"1\ufe0f\u20e3 Multiprocessing Semaphore","text":"<ul> <li>Used to control processes accessing a shared resource.</li> <li>Works like <code>threading.Semaphore</code>, but for multiple processes instead of threads.</li> </ul>"},{"location":"03-concurrency/05-semaphores/#example-multiprocessing-semaphore","title":"Example multiprocessing-semaphore","text":"<pre><code>import multiprocessing\nimport time\n\n# Create a multiprocessing semaphore (max 2 processes can access at a time)\nsemaphore = multiprocessing.Semaphore(2)\n\ndef worker(worker_id):\n    print(f\"Process {worker_id} waiting to access the resource...\")\n    with semaphore:  # Acquire the semaphore\n        print(f\"Process {worker_id} acquired access! \ud83d\ude80\")\n        time.sleep(2)  # Simulate work\n        print(f\"Process {worker_id} released access! \u2705\")\n\n# Create 3 processes\nprocesses = []\nfor i in range(3):\n    p = multiprocessing.Process(target=worker, args=(i,))\n    processes.append(p)\n    p.start()\n\n# Wait for all processes to finish\nfor p in processes:\n    p.join()\n\nprint(\"All processes finished execution!\")\n</code></pre>"},{"location":"03-concurrency/05-semaphores/#expected-behavior","title":"Expected Behavior","text":"<ul> <li>At most 2 processes can access the critical section at the same time.</li> <li>Other processes wait until a slot is freed.</li> </ul>"},{"location":"03-concurrency/05-semaphores/#2-asyncio-semaphore","title":"2\ufe0f\u20e3 Asyncio Semaphore","text":"<ul> <li>Used to limit concurrency in async tasks.</li> <li>Unlike threading/multiprocessing, it does not block but awaits when access is unavailable.</li> </ul>"},{"location":"03-concurrency/05-semaphores/#example-asyncio-semaphore","title":"Example asyncio-semaphore","text":"<pre><code>import asyncio\n\n# Create an asyncio semaphore (max 2 tasks can access at a time)\nsemaphore = asyncio.Semaphore(2)\n\nasync def worker(worker_id):\n    print(f\"Task {worker_id} waiting to access the resource...\")\n    async with semaphore:  # Acquire semaphore asynchronously\n        print(f\"Task {worker_id} acquired access! \ud83d\ude80\")\n        await asyncio.sleep(2)  # Simulating work\n        print(f\"Task {worker_id} released access! \u2705\")\n\nasync def main():\n    tasks = [worker(i) for i in range(3)]\n    await asyncio.gather(*tasks)\n\nasyncio.run(main())\n</code></pre>"},{"location":"03-concurrency/05-semaphores/#expected","title":"Expected","text":"<ul> <li>Two tasks run at the same time.</li> <li>The third task waits until one of them releases the semaphore.</li> </ul>"},{"location":"03-concurrency/05-semaphores/#when-to-use-what","title":"\ud83d\ude80 When to Use What?","text":"Scenario Use Multi-threading <code>threading.Semaphore()</code> Multi-processing <code>multiprocessing.Semaphore()</code> Async I/O operations <code>asyncio.Semaphore()</code>"},{"location":"03-concurrency/06-byte-range-downloader/","title":"Byte-Range downloader code","text":"<ul> <li>This code was written by BhimRaj Yadav.</li> <li>It's a great example of how to use <code>semaphore</code>, <code>asyncio</code> and <code>aiohttp</code> to download files much faster.</li> </ul> <pre><code>import asyncio\nimport aiohttp\nimport time\nfrom aiohttp import ClientSession\nfrom typing import Dict, Optional\nfrom tqdm import tqdm\nimport random\n\n\nasync def download_chunk(\n    session: ClientSession,\n    url: str,\n    start: int,\n    stop: int,\n    headers: Dict[str, str],\n    buffer: bytearray,\n    progress_bar: tqdm,\n    retries: int = 3,\n):\n    \"\"\"Download a specific chunk of the file and write it to the correct position in the buffer.\"\"\"\n    # Make a local copy of headers so that each call has its own header dict\n    local_headers = headers.copy()\n    local_headers.update({\"Range\": f\"bytes={start}-{stop}\"})\n\n    attempt = 0\n    while attempt &lt; retries:\n        try:\n            # print(f\"Downloading chunk {start}-{stop}\")\n            async with session.get(url, headers=local_headers) as response:\n                if response.status != 206:  # 206 Partial Content is expected\n                    raise Exception(\n                        f\"Failed to download chunk {start}-{stop}: HTTP {response.status}\"\n                    )\n                content = await response.read()\n                # Write the downloaded content into the buffer at the correct offset\n                buffer[start : start + len(content)] = content\n\n            # Update progress bar by the number of bytes expected for this chunk.\n            # (Note: the final chunk might be a bit smaller, but that's fine.)\n            progress_bar.update(stop - start + 1)\n            return  # Successful download; exit the loop\n        except Exception as e:\n            print(f\"Error downloading chunk {start}-{stop}: {e}\")\n            attempt += 1\n            if attempt &lt; retries:\n                wait_time = random.uniform(1, 3)\n                print(f\"Retrying chunk {start}-{stop} in {wait_time:.2f} seconds...\")\n                await asyncio.sleep(wait_time)\n            else:\n                print(\n                    f\"Failed to download chunk {start}-{stop} after {retries} retries.\"\n                )\n                raise e\n\n\nasync def download_file(\n    url: str,\n    filename: str,\n    chunk_size: int,\n    max_connections: int,\n    headers: Optional[Dict[str, str]] = None,\n):\n    \"\"\"Download a file in parallel chunks using asyncio and aiohttp, storing data in a preallocated bytearray.\"\"\"\n    headers = headers or {}\n\n    # Get total file size (handling redirects if necessary)\n    async with aiohttp.ClientSession() as session:\n        async with session.head(url, headers=headers) as response:\n            if response.status == 302:\n                location = response.headers.get(\"Location\")\n                if location:\n                    # print(f\"Redirecting to {location}\")\n                    url = location\n                    async with session.head(url, headers=headers) as new_response:\n                        if new_response.status != 200:\n                            raise Exception(\n                                f\"Failed to get file info: HTTP {new_response.status}\"\n                            )\n                        content_length = int(\n                            new_response.headers.get(\"Content-Length\", 0)\n                        )\n                else:\n                    raise Exception(\n                        f\"Failed to get file info: HTTP {response.status} - No Location header found.\"\n                    )\n            elif response.status == 200:\n                content_length = int(response.headers.get(\"Content-Length\", 0))\n            else:\n                raise Exception(f\"Failed to get file info: HTTP {response.status}\")\n\n    print(f\"Total file size: {content_length} bytes\")\n\n    # Preallocate a bytearray for the file\n    buffer = bytearray(content_length)\n\n    with tqdm(\n        total=content_length, unit=\"B\", unit_scale=True, desc=filename\n    ) as progress_bar:\n        tasks = []\n        semaphore = asyncio.Semaphore(max_connections)\n\n        async with aiohttp.ClientSession() as session:\n            for start in range(0, content_length, chunk_size):\n                stop = min(start + chunk_size - 1, content_length - 1)\n                # print(f\"Chunk {start}-{stop} will be downloaded.\")\n\n                # Capture start and stop in the local scope of the task.\n                async def limited_download(start=start, stop=stop):\n                    async with semaphore:\n                        await download_chunk(\n                            session, url, start, stop, headers, buffer, progress_bar\n                        )\n\n                tasks.append(asyncio.create_task(limited_download()))\n\n            await asyncio.gather(*tasks)\n\n        # After downloading all chunks, write the complete buffer to file.\n        with open(filename, \"wb\") as f:\n            f.write(buffer)\n\n\n# Example usage:\nif __name__ == \"__main__\":\n    url = \"https://huggingface.co/microsoft/OmniParser-v2.0/resolve/main/icon_caption/model.safetensors\"\n    filename = \"model-byte-range.safetensors\"\n    chunk_size = 1024 * 1024 * 1  # 1 MB chunks\n    max_connections = 16  # Limit parallel connections\n    print(\n        f\"Downloading with {max_connections} connections and chunk size of {chunk_size} bytes\"\n    )\n\n    start_time = time.time()\n    asyncio.run(download_file(url, filename, chunk_size, max_connections))\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n    print(f\"Download completed in {elapsed_time:.2f} seconds.\")\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/","title":"Multithreading in Python","text":""},{"location":"03-concurrency/01-threading/01-intro/#threads","title":"Threads","text":"<ul> <li>Smallest unit of execution</li> <li>A process can have multiple threads</li> </ul>"},{"location":"03-concurrency/01-threading/01-intro/#types-of-threads","title":"Types of threads","text":"<ol> <li>Main Thread  : The initial thread of execution when the program starts.</li> <li>Daemon Threads  : Background threads that automatically exit when the main thread terminates.</li> <li>Non-Daemon Threads  : Threads that continue to run until they complete their task, even if the main thread exits.</li> </ol>"},{"location":"03-concurrency/01-threading/01-intro/#simple-threading-code","title":"Simple <code>threading</code> code","text":"<p>Info</p> <ul> <li><code>target</code> is the function to be executed</li> <li><code>args</code> is the argument to be passed to the function</li> <li><code>start</code> starts the thread</li> <li><code>join</code> waits for the thread to finish</li> </ul> <pre><code>import threading\n\n\ndef print_cube(num):\n    print(\"Cube: {}\" .format(num * num * num))\n\n\ndef print_square(num):\n    print(\"Square: {}\" .format(num * num))\n\n\nif __name__ ==\"__main__\":\n    t1 = threading.Thread(target=print_square, args=(10,))\n    t2 = threading.Thread(target=print_cube, args=(10,), daemon=True) # daemon thread\n\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n\n    print(\"Done!\")\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/#daemon-threads","title":"Daemon Threads","text":"<ul> <li>By passing <code>daemon=True</code> to the thread, we can make it a daemon thread.</li> <li>Daemon threads are background threads that automatically exit when the main thread terminates.</li> <li>Since daemon threads are abruptly terminated when the program ends, they may not finish their work or clean up resources properly. So, they are ideal for tasks that don't require cleanup or finishing. (like <code>logging</code>, <code>monitoring</code>, etc.)</li> </ul>"},{"location":"03-concurrency/01-threading/01-intro/#threads-name-pid","title":"Thread's name &amp; PID","text":"<ul> <li>all the threads that we will create, will have the same PID.</li> </ul> <pre><code>import threading\nimport os\n\ndef task1():\n    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name))\n    print(\"ID of process running task 1: {}\".format(os.getpid()))\n\ndef task2():\n    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name))\n    print(\"ID of process running task 2: {}\".format(os.getpid()))\n\nif __name__ == \"__main__\":\n\n    print(\"ID of process running main program: {}\".format(os.getpid()))\n\n    print(\"Main thread name: {}\".format(threading.current_thread().name))\n\n    t1 = threading.Thread(target=task1, name='t1')\n    t2 = threading.Thread(target=task2, name='t2')\n\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n</code></pre>"},{"location":"03-concurrency/01-threading/01-intro/#simple-methods-of-threading-module","title":"Simple methods of <code>threading</code> module","text":"<ul> <li><code>active_count()</code> : Returns the number of Thread objects currently alive.</li> <li><code>current_thread()</code> : Returns the current Thread object, corresponding to the caller's thread of control.</li> <li><code>enumerate()</code> : Returns a list of all Thread objects currently alive.</li> <li><code>main_thread()</code> : Returns the main Thread object.</li> </ul> <pre><code>import threading\n\nprint(\"Number of active threads: {}\".format(threading.active_count()))\nprint(\"Current thread: {}\".format(threading.current_thread()))\nprint(\"List of all threads: {}\".format(threading.enumerate()))\nprint(\"Main thread: {}\".format(threading.main_thread()))\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/","title":"Custom Thread","text":"<p>creating custom thread</p> <ul> <li>We can inherit <code>Thread</code> class and create our own implementation of <code>run</code> method.</li> <li>We only need to implement <code>__init__</code> and <code>run</code> method.</li> <li>Then, we can use <code>start</code>, <code>join</code> and other methods as we did with <code>thread</code> class.</li> </ul> <pre><code>from threading import Thread\n\nclass MyThread(Thread):\n    def __init__(self, num):\n        self.num = num\n        super().__init__() # calling the parent class constructor (required)\n\n    def run(self):\n        for i in range(10):\n            print(f\"I'm thread: {self.num} =&gt; {i}\")\n\nif __name__ == \"__main__\":\n    my_t = []\n    for i in range(5):\n        curr_t = MyThread(i+1)\n        my_t.append(curr_t)\n\n    print(\"=== start all the threads ===\")\n    for t in my_t:\n        t.start()\n\n    for t in my_t:\n        t.join()\n\n    print(\"=== all threads finished ===\")\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/#make-custom-daemon-thread","title":"Make custom daemon thread","text":"<ul> <li>to make the thread <code>a daemon thread</code>, we can set <code>daemon=True</code> in the constructor.</li> </ul> <pre><code>super().__init__(daemon=True)\n</code></pre>"},{"location":"03-concurrency/01-threading/02-custom-thread/#methods-of-thread","title":"Methods of Thread","text":"<ol> <li><code>start</code>: This method starts the thread.</li> <li><code>join(timeout=None)</code>: This method waits infinitely for the thread to finish.</li> <li> <p><code>join(timeout)</code>: This method waits for the thread to finish for the specified time. <code>join()</code> method always return <code>None</code>. So to check if the <code>join() method</code> completed bcoz task is over, or due to timeout, we can use <code>is_alive()</code> method.</p> </li> <li> <p>If <code>is_alive()</code> returns <code>True</code>, then the thread is still running, and timeout has occurred (if <code>join(timeout)</code> is completed).</p> </li> </ol>"},{"location":"03-concurrency/01-threading/03-event/","title":"Event in Threading","text":"<ul> <li>communication mechanism b/w threads</li> </ul> <p>one thread signals an event and other threads wait for it.</p> <p>An event object manages an internal flag that can be:</p> <ul> <li>set to <code>true</code> with the <code>set() method</code></li> <li><code>is_set()</code> return True if and only if the internal flag is true.</li> <li>and <code>reset</code> to false with the <code>clear() method</code>.</li> <li>The <code>wait(timeout=None)</code> method blocks until the flag is true.</li> <li>If timeout of wait is not None (a floating point), it will wait for the flag to be set for the specified time, and then return <code>True</code> if the flag is set, otherwise <code>False</code>.</li> </ul>"},{"location":"03-concurrency/01-threading/03-event/#code","title":"Code","text":"<ul> <li>A sample code:</li> </ul> <pre><code>from threading import Thread, Event\nimport time\nimport threading\n\n# Create an Event object\nevent = Event()\n\n# Function that waits for the event to be set\ndef worker():\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set=}\")\n\n# Start a thread that runs the worker function\nthread = Thread(target=worker)\nthread.start()\n\n# Simulate some delay\ntime.sleep(2)\nprint(\"Main thread setting the event!\")\nevent.set()  # Signal the worker to proceed\n</code></pre>"},{"location":"03-concurrency/02-processing/01-intro/","title":"Multiprocessing in Python","text":"<ul> <li>Utilize multiple processors to speed up your code</li> <li>Escaping the GIL</li> <li><code>multiprocessing's process</code> is analogous to <code>threading's thread</code>. They hvae similar APIs.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#methods-to-start-new-process","title":"Methods to start new process","text":"<p><code>multiprocessing</code> supports three ways to start a process:</p> <ul> <li>Fork: Creates a new process by copying the parent, making it the fastest but potentially risky due to shared resources (UNIX only). <code>Fork is fast, potentially unsafe, and may carry unnecessary data from the parent, though Copy-On-Write mitigates this</code>.</li> <li>Spawn: Starts a clean process from scratch, ensuring safety and isolation but at the cost of slower startup (default on Windows). <code>While slower, this is the safest option, especially for long-running or resource-sensitive tasks</code>.</li> <li>Forkserver: Uses a dedicated server to spawn processes, combining safety with moderate performance overhead (UNIX only). <code>Though less commonly used due to setup complexity and limited documentation, it\u2019s useful for controlled multi-process environments</code>.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#set-get-process-start-method","title":"Set &amp; Get <code>process start method</code>","text":"<ul> <li>To select a start method you use the <code>set_start_method()</code> in the if <code>__name__ == '__main__'</code> clause of the main module.</li> </ul> <pre><code>import multiprocessing as mp\n\nprint(mp.get_start_method())  # Get the current start method\n\nif __name__ == '__main__':\n    mp.set_start_method('forkserver')  # Set the start method\n</code></pre> <ul> <li>set_start_method() should not be used more than once in the program.</li> </ul>"},{"location":"03-concurrency/02-processing/01-intro/#simple-multiprocessing-example","title":"Simple multiprocessing example","text":"<pre><code># importing the multiprocessing module\nfrom multiprocessing import Process\nimport os\n\ndef print_cube(num):\n    \"\"\"\n    function to print cube of given num\n    \"\"\"\n    print(\"Cube: {}; and {}\".format(num * num * num, os.getpid()))\n\ndef print_square(num):\n    \"\"\"\n    function to print square of given num\n    \"\"\"\n    print(\"Square: {}; and {}\".format(num * num, os.getpid()))\n\nif __name__ == \"__main__\":\n    # creating processes\n    p1 = Process(target=print_square, args=(10, ))\n    p2 = Process(target=print_cube, args=(10, ))\n\n    # starting process 1\n    p1.start()\n    # starting process 2\n    p2.start()\n\n    # wait until process 1 is finished\n    p1.join()\n    # wait until process 2 is finished\n    p2.join()\n\n    # both processes finished\n    print(\"Done!\")\n</code></pre> <p>Info</p> <p><code>Process</code> has very similar API to <code>Thread</code> in <code>threading</code> module.</p> <ul> <li><code>start()</code>, <code>join()</code>, <code>is_alive()</code>, etc.</li> <li><code>Process</code> also provides a <code>terminal()</code> and <code>kill()</code> method to terminate a process.</li> <li><code>target</code> is the function to be executed by the process.</li> <li><code>args</code> is the arguments to be passed to the target function.</li> </ul> <p></p>"},{"location":"03-concurrency/02-processing/02-communication/","title":"Communication in Multiprocessing","text":"<ul> <li>Processes can push values to a queue and pull values from a queue(<code>most important</code>).</li> <li>Two processes can communicate with each other using a pipe.</li> <li>Processes can share memory using shared memory objects. If one process changes the value, the other process can see the change.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#shared-memory","title":"Shared Memory","text":""},{"location":"03-concurrency/02-processing/02-communication/#value","title":"<code>Value</code>","text":"<ul> <li><code>Value</code> is a shared memory object that allows you to store a single value.</li> <li>Specify the type of the value and the initial value.</li> <li>Read and write the value using the <code>value</code> attribute.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#array","title":"<code>Array</code>","text":"<ul> <li><code>Array</code> is a shared memory object that allows you to store a sequence of values.</li> <li>Specify the type of the value and the length.</li> </ul> <pre><code>from multiprocessing import Process, Value, Array\n\ndef f(n, a):\n    n.value = 3.1415927\n    for i in range(len(a)):\n        a[i] = -a[i]\n\nif __name__ == '__main__':\n    num = Value('d', 0.0)\n    arr = Array('i', range(10))\n\n    p = Process(target=f, args=(num, arr))\n    p.start()\n    p.join()\n\n    print(num.value)\n    print(arr[:])\n</code></pre>"},{"location":"03-concurrency/02-processing/02-communication/#queue","title":"Queue","text":"<ul> <li><code>Queue</code> is a thread and process-safe queue.</li> <li>It allows multiple processes to push and pull values from the queue.</li> </ul> <pre><code>from multiprocessing import Process, Queue\n\ndef f(q):\n    q.put([42, None, 'hello'])\n\nif __name__ == '__main__':\n    q = Queue()\n    p = Process(target=f, args=(q,))\n    p.start()\n    print(q.get())    # prints \"[42, None, 'hello']\"\n    p.join()\n</code></pre> <p>methods of Queue</p> <ul> <li><code>put(obj, block=True, timeout=None)</code>: Push a value to the queue. If queue is full, block and wait until the queue doesn't have any space, then push. If timeout is not None, it will wait for the specified time, and then raise <code>queue.Full</code> exception if the queue is still full.</li> <li><code>put_nowait(obj)</code>: Push a value to the queue. If the queue is full, raise <code>queue.Full</code> exception.</li> <li><code>get(block=True, timeout=None)</code>: Pull a value from the queue. If no value is available, block and wait until a value is available. If timeout is not None, it will wait for the specified time, and then raise <code>queue.Empty</code> exception if the queue is still empty.</li> <li><code>get_nowait()</code>: Pull a value from the queue. If no value is available, raise <code>queue.Empty</code> exception.</li> <li><code>empty()</code>: Return <code>True</code> if the queue is empty.</li> <li><code>full()</code>: Return <code>True</code> if the queue is full.</li> <li><code>qsize()</code>: Return the number of items in the queue.</li> <li><code>close()</code>: Close the queue.</li> <li><code>join_thread()</code>: Join the background thread. This can only be used after close() has been called. It blocks until the background thread exits, ensuring that all data in the buffer has been flushed to the pipe.</li> </ul>"},{"location":"03-concurrency/02-processing/02-communication/#pipe","title":"Pipe","text":"<ul> <li><code>Pipe</code> is a two-way communication channel between two processes.</li> <li>It returns two connection objects that represent the two ends of the pipe.</li> <li>Both connection objects have <code>send()</code> and <code>recv()</code> methods.</li> <li>data in a pipe may become corrupted if two processes (or threads) try to read from or write to the same end of the pipe at the same time.</li> <li>Of course there is no risk of corruption from processes using different ends of the pipe at the same time.</li> </ul> <pre><code>from multiprocessing import Process, Pipe\n\ndef f(conn):\n    conn.send([42, None, 'hello'])\n    conn.close()\n\nif __name__ == '__main__':\n    parent_conn, child_conn = Pipe()\n    p = Process(target=f, args=(child_conn,))\n    p.start()\n    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n    p.join()\n</code></pre> <ul> <li>Each connection object (<code>parent_conn</code> &amp; <code>child_conn</code>) returned by pipe have multiple ways to transfer data.</li> </ul> <p>connection object methods</p> <ul> <li><code>send()</code>: Send data to the other end of the pipe.</li> <li><code>recv()</code>: Receive data from the other end of the pipe.</li> <li><code>poll(timeout=None)</code>: Return <code>True</code> if there is any data to read.</li> <li><code>send_bytes(buffer)</code>: Send a bytes object.</li> <li><code>recv_bytes(maxlength)</code>: Receive a bytes object.</li> <li><code>recv_bytes_into(buffer)</code>: Receive a bytes object into a buffer.</li> </ul> <pre><code>&gt;&gt;&gt; from multiprocessing import Pipe\n&gt;&gt;&gt;\n&gt;&gt;&gt; a, b = Pipe()\n&gt;&gt;&gt;\n&gt;&gt;&gt; a.send([1, 'hello', None])\n&gt;&gt;&gt; b.recv()\n[1, 'hello', None]\n&gt;&gt;&gt;\n&gt;&gt;&gt; b.send_bytes(b'thank you')\n&gt;&gt;&gt; a.recv_bytes()\nb'thank you'\n&gt;&gt;&gt;\n&gt;&gt;&gt; import array\n&gt;&gt;&gt;\n&gt;&gt;&gt; arr1 = array.array('i', range(5))\n&gt;&gt;&gt; arr2 = array.array('i', [0] * 10)\n&gt;&gt;&gt;\n&gt;&gt;&gt; a.send_bytes(arr1)\n&gt;&gt;&gt; count = b.recv_bytes_into(arr2)\n&gt;&gt;&gt; assert count == len(arr1) * arr1.itemsize\n&gt;&gt;&gt; arr2\narray('i', [0, 1, 2, 3, 4, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/","title":"Locking &amp; Event in Multiprocessing","text":""},{"location":"03-concurrency/02-processing/03-locking/#lock","title":"Lock","text":"<ul> <li><code>Lock</code> is a synchronization primitive that allows only one process to access a shared resource at a time.</li> <li>it has two methods <code>acquire(block=True, timeout=None)</code> and <code>release()</code>.</li> </ul> <pre><code>from multiprocessing import Process, Lock\n\ndef f(l, i):\n    l.acquire()\n    try:\n        print('hello world', i)\n    finally:\n        l.release()\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start()\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/#lock-with-context-manager","title":"Lock with context manager","text":"<ul> <li>Lock can also be used as a context manager.</li> <li>It automatically acquires the lock before the block and releases it after the block.</li> </ul> <pre><code>from multiprocessing import Process, Lock\n\ndef f(l, i):\n    with l:\n        print('hello world', i)\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start()\n</code></pre>"},{"location":"03-concurrency/02-processing/03-locking/#event","title":"Event","text":"<ul> <li>Similar to threading, <code>Event</code> is a communication mechanism between processes.</li> <li>one process signals an event and other process wait for it.</li> </ul> <p>An event object manages an internal flag that can be:</p> <ul> <li>set to <code>true</code> with the <code>set() method</code></li> <li><code>is_set()</code> return True if and only if the internal flag is true.</li> <li>and <code>reset</code> to false with the <code>clear() method</code>.</li> <li>The <code>wait(timeout=None)</code> method blocks until the flag is true.</li> <li>If timeout of wait is not None (a floating point), it will wait for the flag to be set for the specified time, and then return <code>True</code> if the flag is set, otherwise <code>False</code>.</li> </ul>"},{"location":"03-concurrency/02-processing/03-locking/#event-object-in-multiprocessing-are-not-shared-bw-processes","title":"Event object in multiprocessing are not shared b/w processes \u274c\ud83d\udc47\ud83c\udffb","text":"<pre><code>from multiprocessing import Process, Event\nimport time\nimport multiprocessing\n\n# Create an Event object\nevent = Event()\n\n# Function that waits for the event to be set\ndef worker():\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set=}\")\n\n# Start a thread that runs the worker function\np = Process(target=worker)\np.start()\n\n# Simulate some delay\ntime.sleep(2)\nprint(\"Main thread setting the event!\")\nevent.set()  # Signal the worker to proceed\n</code></pre> <p>Event object in multiprocessing are not shared b/w processes</p> <p>The above code will not work as expected. The event object is not shared between processes. The worker process will not be able to see the event set by the main process.</p> <ul> <li>We need to use <code>manager.Event()</code> to create an event object that is shared between processes.</li> </ul>"},{"location":"03-concurrency/02-processing/03-locking/#multiprocessing-manager","title":"Multiprocessing manager","text":"<pre><code>from multiprocessing import Process, Event, Manager\nimport time\n\ndef worker(event):\n    print(f\"Worker is waiting for the event...{event.is_set()=}\")\n    event.wait()  # Wait until the event is set\n    print(f\"Worker is proceeding! {event.is_set()=}\")\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        # Create a shared Event object\n        event = manager.Event()\n\n        # Start a process that runs the worker function\n        p = Process(target=worker, args=(event,))\n        p.start()\n\n        # Simulate some delay\n        time.sleep(2)\n        print(\"Main process setting the event!\")\n        event.set()  # Signal the worker to proceed\n        p.join()\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/","title":"Manager in Python Multiprocessing","text":""},{"location":"03-concurrency/02-processing/04-manager/#what-is-a-manager","title":"What is a Manager?","text":"<ul> <li>A <code>Manager</code> in Python's <code>multiprocessing</code> module provides a way to create and manage shared objects between processes.</li> <li>Shared objects include lists, dictionaries, Events, Locks, and more.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#why-use-a-manager","title":"Why Use a Manager?","text":"<ul> <li>Processes in Python have separate memory spaces.</li> <li>Without a <code>Manager</code>, objects created in one process are not automatically shared with others.</li> <li>A <code>Manager</code> allows processes to interact with shared objects safely.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Sharing data structures like lists or dictionaries between processes.</li> <li>Synchronizing processes using shared objects like <code>Event</code> or <code>Lock</code>.</li> </ol>"},{"location":"03-concurrency/02-processing/04-manager/#how-to-use-a-manager","title":"How to Use a Manager?","text":""},{"location":"03-concurrency/02-processing/04-manager/#basic-syntax","title":"Basic Syntax","text":"<pre><code>from multiprocessing import Manager\n\nwith Manager() as manager:\n    shared_list = manager.list()  # Create a shared list\n    shared_dict = manager.dict()  # Create a shared dictionary\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#example-shared-dictionary","title":"Example: Shared Dictionary","text":"<pre><code>from multiprocessing import Process, Manager\n\ndef worker(shared_dict):\n    shared_dict[\"key\"] = \"value\"  # Update the shared dictionary\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        shared_dict = manager.dict()  # Create a shared dictionary\n        p = Process(target=worker, args=(shared_dict,))\n        p.start()\n        p.join()\n        print(shared_dict)  # Output: {'key': 'value'}\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#example-shared-event","title":"Example: Shared Event","text":"<pre><code>from multiprocessing import Process, Manager\n\ndef worker(event):\n    print(\"Waiting for event...\")\n    event.wait()  # Wait for the event to be set\n    print(\"Event is set!\")\n\nif __name__ == \"__main__\":\n    with Manager() as manager:\n        event = manager.Event()  # Create a shared Event\n        p = Process(target=worker, args=(event,))\n        p.start()\n        event.set()  # Set the event\n        p.join()\n</code></pre>"},{"location":"03-concurrency/02-processing/04-manager/#advantages","title":"Advantages","text":"<ul> <li>Provides easy sharing of objects across processes.</li> <li>Manages synchronization safely and avoids manual complexity.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#disadvantages","title":"Disadvantages","text":"<ul> <li>Slower than using shared memory (e.g., <code>multiprocessing.Value</code> or <code>multiprocessing.Array</code>) because communication is handled via a server process.</li> <li>Overhead for small or frequent updates.</li> </ul>"},{"location":"03-concurrency/02-processing/04-manager/#when-to-use-a-manager","title":"When to Use a Manager?","text":"<ul> <li>Use a <code>Manager</code> when you need to share complex data structures or synchronization primitives like <code>Event</code> or <code>Lock</code>.</li> <li>For performance-critical tasks with simple data, prefer shared memory objects.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/","title":"Process Pools in Python Multiprocessing","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#what-is-a-process-pool","title":"What is a Process Pool?","text":"<ul> <li>A <code>ProcessPool</code> is a pool of worker processes used to execute tasks concurrently.</li> <li>It simplifies the management of multiple processes, especially when there are many tasks to distribute.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#why-use-a-process-pool","title":"Why Use a Process Pool?","text":"<ul> <li>To execute tasks in parallel across multiple processes without manually managing them.</li> <li>To reuse worker processes, reducing the overhead of creating and destroying processes repeatedly.</li> <li>Provides an easy-to-use interface for parallel execution.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#key-methods-of-process-pools","title":"Key Methods of Process Pools","text":"<ol> <li><code>apply()</code>: Executes a single task in a process and waits for the result (blocking).</li> <li><code>apply_async()</code>: Executes a single task asynchronously and returns a <code>AsyncResult</code> object (non-blocking).</li> <li><code>map()</code>: Distributes an iterable of tasks across processes and collects results (blocking).</li> <li><code>map_async()</code>: Same as <code>map()</code> but non-blocking.</li> <li><code>starmap()</code>: Similar to <code>map()</code> but supports multiple arguments for each task. <code>map doesn't support multiple argument</code>.</li> <li><code>imap()</code>: Lazily returns an iterator to results as they become available.</li> </ol>"},{"location":"03-concurrency/02-processing/05-process-pool/#how-to-use-a-process-pool","title":"How to Use a Process Pool?","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#basic-syntax","title":"Basic Syntax","text":"<pre><code>from multiprocessing import Pool\n\nwith Pool(processes=4) as pool:  # Create a pool with 4 worker processes\n    result = pool.map(func, iterable)\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#examples","title":"Examples","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#1-using-map","title":"1. Using <code>map()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef square(x):\n    return x * x\n\nif __name__ == \"__main__\":\n    with Pool(processes=4) as pool:\n        results = pool.map(square, [1, 2, 3, 4])\n    print(results)  # Output: [1, 4, 9, 16]\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#2-using-apply_async","title":"2. Using <code>apply_async()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef cube(x):\n    return x ** 3\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        result = pool.apply_async(cube, (3,))\n        print(result.get())  # Output: 27\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#3-using-starmap","title":"3. Using <code>starmap()</code>","text":"<pre><code>from multiprocessing import Pool\n\ndef add(a, b):\n    return a + b\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        results = pool.starmap(add, [(1, 2), (3, 4), (5, 6)])\n    print(results)  # Output: [3, 7, 11]\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#map-vs-imap-vs-imap_unordered","title":"Map Vs iMap vs imap_unordered","text":"<p>The <code>imap()</code> function in Python's <code>multiprocessing.Pool</code> is a variant of <code>map()</code> that processes tasks lazily, meaning it returns an iterator instead of a fully-evaluated list. This can be beneficial when working with large datasets because results are produced and consumed one at a time, avoiding the need to store all results in memory at once.</p>"},{"location":"03-concurrency/02-processing/05-process-pool/#key-differences-between-map-and-imap","title":"Key Differences Between <code>map()</code> and <code>imap()</code>","text":"Feature <code>map()</code> <code>imap()</code> Return Type List (eager evaluation) Iterator (lazy evaluation) Memory Usage Stores all results in memory Produces results one at a time Use Case Small-to-medium datasets Large datasets where memory is a concern"},{"location":"03-concurrency/02-processing/05-process-pool/#example-of-imap","title":"Example of <code>imap()</code>","text":"<pre><code>from multiprocessing import Pool\nimport time\n\ndef slow_square(x):\n    time.sleep(1)  # Simulate a slow computation\n    return x * x\n\nif __name__ == \"__main__\":\n    with Pool(processes=2) as pool:\n        results = pool.imap(slow_square, [1, 2, 3, 4, 5])\n\n        # Process results as they are ready\n        for result in results:\n            print(result)\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#output-one-result-every-second","title":"Output (one result every second):","text":"<pre><code>1\n4\n9\n16\n25\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#why-use-imap","title":"Why Use <code>imap()</code>?","text":"<ul> <li>Memory Efficiency:  </li> </ul> <p>Instead of generating and storing all results at once, <code>imap()</code> produces them incrementally. Useful when working with large input datasets or when the task is memory-intensive.</p> <ul> <li>Time Efficiency:  </li> </ul> <p>If you want to start processing results as they are computed, <code>imap()</code> enables this instead of waiting for all tasks to complete like <code>map()</code>.</p>"},{"location":"03-concurrency/02-processing/05-process-pool/#variants","title":"Variants:","text":"<ul> <li><code>imap_unordered()</code>:</li> <li>Similar to <code>imap()</code> but does not preserve the order of results.</li> <li>Results are returned as soon as individual tasks are completed, regardless of their order in the input.</li> <li> <p>Useful for maximizing throughput when the order of results doesn't matter.</p> </li> </ul> <pre><code>with Pool(processes=2) as pool:\n    results = pool.imap_unordered(slow_square, [1, 2, 3, 4, 5])\n    for result in results:\n        print(result)  # Results might appear out of order\n</code></pre>"},{"location":"03-concurrency/02-processing/05-process-pool/#example","title":"Example","text":""},{"location":"03-concurrency/02-processing/05-process-pool/#advantages","title":"Advantages","text":"<ul> <li>Simplifies parallel execution of tasks.</li> <li>Automatically handles process management (creation, destruction, and task distribution).</li> <li>Efficient for CPU-bound tasks that benefit from parallelism.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#disadvantages","title":"Disadvantages","text":"<ul> <li>Limited to functions (cannot directly use methods tied to objects).</li> <li>Overhead in creating and managing the pool can be significant for very lightweight tasks.</li> </ul>"},{"location":"03-concurrency/02-processing/05-process-pool/#when-to-use-a-process-pool","title":"When to Use a Process Pool?","text":"<ul> <li>Use a <code>ProcessPool</code> for independent, parallelizable tasks that are CPU-bound and can benefit from multiple processes.</li> <li>Avoid using it for I/O-bound tasks\u2014for such tasks, consider using ThreadPoolExecutor or asynchronous programming.</li> </ul>"},{"location":"03-concurrency/02-processing/06-custom-process/","title":"Custom Process","text":""},{"location":"03-concurrency/02-processing/06-custom-process/#why-create-a-custom-process","title":"Why Create a Custom Process?","text":"<ul> <li>Subclassing <code>multiprocessing.Process</code> is useful when you need to encapsulate specific data or behavior for each process. (Like LitData DataWorker, a process class that downloads data, processes it, and saves it to a database.)</li> <li>Allows defining a custom <code>run()</code> method, which will be executed when the process starts.</li> </ul>"},{"location":"03-concurrency/02-processing/06-custom-process/#implementation","title":"Implementation \ud83e\udd13","text":"<p>creating custom process</p> <ul> <li>Very similar to <code>creating custom thread</code>.</li> <li>We can inherit <code>Process</code> class and create our own implementation of <code>run</code> method.</li> <li>We only need to implement <code>__init__</code> and <code>run</code> method.</li> <li>Then, we can use <code>start</code>, <code>join</code> and other methods as we did with <code>Process</code> class.</li> </ul> <pre><code>from multiprocessing import Process\n\nclass MyProcess(Process):\n    def __init__(self, num):\n        self.num = num\n        super().__init__() # calling the parent class constructor (required)\n\n    def run(self):\n        for i in range(10):\n            print(f\"I'm process: {self.num} =&gt; {i}\")\n\nif __name__ == \"__main__\":\n    my_p = []\n    for i in range(5):\n        curr_p = MyProcess(i+1)\n        my_p.append(curr_p)\n\n    print(\"=== start all the processes ===\")\n    for p in my_p:\n        p.start()\n\n    for p in my_p:\n        p.join()\n\n    print(\"=== all processes finished ===\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/01-intro/","title":"AsyncIO","text":"<ul> <li>asyncio is a library to write concurrent code using the async/await syntax.</li> </ul> <p>asyncio is often a perfect fit for IO-bound and high-level structured network code.</p>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/","title":"High-Level APIs of <code>asyncio</code>","text":"<p><code>asyncio</code> is Python's library for asynchronous programming, allowing you to run tasks concurrently without using threads or processes.</p>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#key-concepts","title":"Key Concepts","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#1-coroutine","title":"1. Coroutine","text":"<ul> <li>A function defined using <code>async def</code>.</li> <li>Can be paused and resumed using <code>await</code>.</li> <li>Example:</li> </ul> <pre><code>async def my_coroutine():\n    await asyncio.sleep(1)  # Pause for 1 second\n    print(\"Done!\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#2-event-loop","title":"2. Event Loop","text":"<ul> <li>Manages the execution of coroutines and tasks.</li> <li>High-level APIs automatically handle the event loop for you.</li> </ul>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#3-task","title":"3. Task","text":"<ul> <li>A coroutine wrapped in a <code>Task</code> object, which runs concurrently.</li> <li>Created using <code>asyncio.create_task()</code>.</li> </ul>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#high-level-functions","title":"High-Level Functions","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#1-asyncioruncoro","title":"1. <code>asyncio.run(coro)</code>","text":"<ul> <li>Runs the given coroutine and closes the event loop after completion.</li> <li>Use it as the entry point for your asynchronous program.</li> <li>Example:</li> </ul> <pre><code>async def main():\n    print(\"Hello, asyncio!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#2-asynciogathercoros","title":"2. <code>asyncio.gather(*coros)</code>","text":"<ul> <li>Runs multiple coroutines concurrently and collects their results.</li> <li>Results are returned in the same order as the coroutines were passed.</li> <li>Example:</li> </ul> <pre><code>async def task(name, delay):\n    await asyncio.sleep(delay)\n    return f\"Task {name} done\"\n\nasync def main():\n    results = await asyncio.gather(task(\"A\", 2), task(\"B\", 1))\n    print(results)  # Output: ['Task A done', 'Task B done']\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#3-asynciocreate_taskcoro","title":"3. <code>asyncio.create_task(coro)</code>","text":"<ul> <li>Starts a coroutine as a background task and returns a <code>Task</code> object.</li> <li>The task runs concurrently with other coroutines.</li> <li>Example:</li> </ul> <pre><code>async def task(name, delay):\n    await asyncio.sleep(delay)\n    print(f\"{name} finished\")\n\nasync def main():\n    t1 = asyncio.create_task(task(\"Task 1\", 2))\n    t2 = asyncio.create_task(task(\"Task 2\", 1))\n    await t1\n    await t2\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#4-await-asynciosleepseconds","title":"4. <code>await asyncio.sleep(seconds)</code>","text":"<ul> <li>Asynchronously pauses execution for the given number of seconds.</li> <li>Allows other tasks to run during the pause.</li> <li>Example:</li> </ul> <pre><code>async def main():\n    print(\"Start\")\n    await asyncio.sleep(1)\n    print(\"End after 1 second\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#error-handling","title":"Error Handling","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#catching-exceptions-in-gather","title":"Catching Exceptions in <code>gather</code>","text":"<ul> <li>Use <code>try/except</code> around <code>asyncio.gather()</code> to catch exceptions from any coroutine.</li> <li>Example:</li> </ul> <pre><code>async def faulty_task():\n    raise ValueError(\"Something went wrong\")\n\nasync def main():\n    try:\n        await asyncio.gather(faulty_task())\n    except Exception as e:\n        print(f\"Caught exception: {e}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#return_exceptionstrue-in-gather","title":"<code>return_exceptions=True</code> in <code>gather</code>","text":"<ul> <li>Collect exceptions without canceling other tasks.</li> <li>Example:</li> </ul> <pre><code>async def faulty_task():\n    raise ValueError(\"Something went wrong\")\n\nasync def main():\n    results = await asyncio.gather(\n        faulty_task(),\n        asyncio.sleep(1),\n        return_exceptions=True\n    )\n    print(results)  # Output: [ValueError('Something went wrong'), None]\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#common-patterns","title":"Common Patterns","text":""},{"location":"04-network-and-ipc/01-async/02-high-level-api/#run-coroutines-concurrently","title":"Run Coroutines Concurrently","text":"<p>Use <code>gather</code> or <code>create_task</code> for concurrency:</p> <pre><code>async def task1():\n    await asyncio.sleep(2)\n    print(\"Task 1 done\")\n\nasync def task2():\n    await asyncio.sleep(1)\n    print(\"Task 2 done\")\n\nasync def main():\n    await asyncio.gather(task1(), task2())  # Runs both tasks concurrently\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#cancel-a-task","title":"Cancel a Task","text":"<pre><code>async def main():\n    task = asyncio.create_task(asyncio.sleep(10))\n    await asyncio.sleep(1)\n    task.cancel()  # Cancels the task\n    try:\n        await task\n    except asyncio.CancelledError:\n        print(\"Task was cancelled!\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/02-high-level-api/#summary","title":"Summary","text":"<ol> <li>Use <code>async def</code> and <code>await</code> to define and run coroutines.</li> <li>Use <code>asyncio.run</code> to execute your main coroutine.</li> <li>Use <code>asyncio.gather</code> or <code>create_task</code> for concurrency.</li> <li>Handle errors with <code>try/except</code> or <code>return_exceptions=True</code>.</li> </ol>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/","title":"Low-Level Overview of <code>asyncio</code>","text":"<p>The low-level APIs in <code>asyncio</code> provide finer control over the event loop, tasks, and protocols. These are useful for advanced use cases like integrating <code>asyncio</code> with custom frameworks or building servers.</p>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#key-low-level-apis","title":"Key Low-Level APIs","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-event-loop","title":"1. Event Loop","text":"<ul> <li>The event loop manages the execution of asynchronous tasks and handles I/O.</li> <li>Use <code>asyncio.get_event_loop()</code> or <code>asyncio.new_event_loop()</code> to work with it.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def main():\n    print(\"Running in the event loop\")\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())  # Manually run the coroutine\nloop.close()  # Always close the loop when done\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-future","title":"2. Future","text":"<ul> <li>A placeholder for a result that hasn\u2019t been computed yet.</li> <li>Usually created internally by <code>asyncio</code>, but you can use it manually.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nloop = asyncio.get_event_loop()\nfuture = loop.create_future()\n\n# Set the result of the future\nloop.call_soon(future.set_result, \"Result is ready\")\n\n# Get the result\nprint(loop.run_until_complete(future))  # Output: \"Result is ready\"\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#3-task","title":"3. Task","text":"<ul> <li>A <code>Task</code> is a coroutine that is being executed by the event loop.</li> <li>You can use <code>asyncio.create_task()</code> (high-level) or <code>loop.create_task()</code> (low-level) to create tasks.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def say_hello():\n    await asyncio.sleep(1)\n    print(\"Hello!\")\n\nloop = asyncio.get_event_loop()\ntask = loop.create_task(say_hello())  # Manually create a task\nloop.run_until_complete(task)\nloop.close()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#4-custom-event-loop","title":"4. Custom Event Loop","text":"<ul> <li>You can create and manage a custom event loop for advanced use cases.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def my_task():\n    await asyncio.sleep(1)\n    print(\"Task completed!\")\n\n# Create a new event loop\ncustom_loop = asyncio.new_event_loop()\nasyncio.set_event_loop(custom_loop)\n\ncustom_loop.run_until_complete(my_task())\ncustom_loop.close()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#low-level-tasks-management","title":"Low-Level Tasks Management","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-loopcall_soon","title":"1. <code>loop.call_soon()</code>","text":"<ul> <li>Schedules a callback to be executed as soon as possible.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef my_callback():\n    print(\"Callback executed!\")\n\nloop = asyncio.get_event_loop()\nloop.call_soon(my_callback)\nloop.run_forever()  # Will execute the callback and then keep running\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-loopcall_later","title":"2. <code>loop.call_later()</code>","text":"<ul> <li>Schedules a callback to be executed after a specific delay.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef delayed_callback():\n    print(\"Callback executed after delay!\")\n\nloop = asyncio.get_event_loop()\nloop.call_later(2, delayed_callback)  # 2-second delay\nloop.run_forever()\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#custom-futures-and-tasks","title":"Custom Futures and Tasks","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#1-using-asynciofuture","title":"1. Using <code>asyncio.Future</code>","text":"<ul> <li>Create your own placeholder for asynchronous results.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\ndef set_future_result(future):\n    future.set_result(\"Future is done!\")\n\nloop = asyncio.get_event_loop()\nfuture = asyncio.Future()\n\nloop.call_soon(set_future_result, future)\nprint(loop.run_until_complete(future))  # Output: \"Future is done!\"\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#2-running-coroutines-as-tasks","title":"2. Running Coroutines as Tasks","text":"<ul> <li>Coroutines need to be wrapped in a <code>Task</code> for the event loop to execute them.</li> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def my_task():\n    print(\"Task running...\")\n    await asyncio.sleep(1)\n    print(\"Task finished!\")\n\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(my_task())  # Wrap coroutine in a Task\nloop.run_until_complete(task)\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#usage","title":"Usage","text":"<pre><code>async def set_after(fut, delay, value):\n    # Sleep for *delay* seconds.\n    await asyncio.sleep(delay)\n\n    # Set *value* as a result of *fut* Future.\n    fut.set_result(value)\n\nasync def main():\n    # Get the current event loop.\n    loop = asyncio.get_running_loop()\n\n    # Create a new Future object.\n    fut = loop.create_future()\n\n    # Run \"set_after()\" coroutine in a parallel Task.\n    # We are using the low-level \"loop.create_task()\" API here because\n    # we already have a reference to the event loop at hand.\n    # Otherwise we could have just used \"asyncio.create_task()\".\n    loop.create_task(\n        set_after(fut, 1, '... world'))\n\n    print('hello ...')\n\n    # Wait until *fut* has a result (1 second) and print it.\n    print(await fut)\n\nasyncio.run(main())\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#error-handling-in-low-level-apis","title":"Error Handling in Low-Level APIs","text":""},{"location":"04-network-and-ipc/01-async/03-low-level-api/#handle-task-exceptions","title":"Handle Task Exceptions","text":"<ul> <li>Example:</li> </ul> <pre><code>import asyncio\n\nasync def faulty_task():\n    raise ValueError(\"Oops!\")\n\nloop = asyncio.get_event_loop()\ntask = loop.create_task(faulty_task())\n\ntry:\n    loop.run_until_complete(task)\nexcept ValueError as e:\n    print(f\"Caught exception: {e}\")\n</code></pre>"},{"location":"04-network-and-ipc/01-async/03-low-level-api/#summary","title":"Summary","text":"<ul> <li>Low-level APIs are for fine-grained control, like managing custom event loops or working with protocols and transports.</li> <li>Use Futures to represent pending results, and Tasks to run coroutines concurrently.</li> <li>Low-level APIs are generally for advanced use cases; stick to high-level APIs for most tasks.</li> </ul>"},{"location":"04-network-and-ipc/01-async/04-async-event/","title":"Async Event (<code>Synchronization Primitives</code>)","text":"<ul> <li>An asyncio event can be used to notify multiple asyncio tasks that some event has happened.</li> </ul> <p>An Event object manages an internal flag that can be set to true with the set() method and reset to false with the clear() method.</p> <p>The wait() method blocks until the flag is set to true. The flag is set to false initially.</p> <pre><code>import asyncio\n\nasync def waiter(event):\n    print('waiting for it ...')\n    await event.wait()\n    print('... got it!')\n\nasync def main():\n    # Create an Event object.\n    event = asyncio.Event()\n\n    # Spawn a Task to wait until 'event' is set.\n    waiter_task = asyncio.create_task(waiter(event))\n\n    # Sleep for 1 second and set the event.\n    await asyncio.sleep(1)\n    event.set()\n\n    # Wait until the waiter task is finished.\n    await waiter_task\n\nasyncio.run(main())\n</code></pre>"},{"location":"05-libraries/01-pytest/01-install-and-config/","title":"Pytest Installation &amp; Configuration","text":""},{"location":"05-libraries/01-pytest/01-install-and-config/#install","title":"Install","text":"<pre><code>pip install -U pytest\n\npytest --version\n</code></pre>"},{"location":"05-libraries/01-pytest/01-install-and-config/#running-pytest","title":"Running pytest","text":"<pre><code># run testfile\npytest test_file_name.py\n\n# run testfile in some nested dir\npytest test_dir1/test_dir2/test_file.py\n\n# running a specific test\npytest test_dir1/test_file.py::my_test_name\n\n# Specifying a specific test method\npytest tests/test_mod.py::TestClass::test_method\n\n# Specifying a specific parametrization of a test\npytest tests/test_mod.py::test_func[x1,y2]\n\n# marker expressions: run all tests decorated with `@pytest.mark.slow`\npytest -m slow\n\n# marker expression: `@pytest.mark.slow(phase=1)`\npytest -m \"slow(phase=1)\"\n</code></pre> <p>pytest options</p> <ul> <li><code>-q</code>: Run in quiet mode (minimal output).  </li> <li><code>-v</code>: Run in verbose mode (detailed output).  </li> <li><code>-s</code> (stdout): Disable output capturing (prints <code>print()</code> statements).  </li> <li><code>--tb=short</code>: Show a shortened traceback for test failures.  </li> <li><code>-k \"expression\" (keyword)</code>: Run tests matching the given substring or expression.</li> </ul>"},{"location":"05-libraries/01-pytest/01-install-and-config/#test-discovery-rule","title":"Test discovery rule","text":"<p>standard test discovery</p> <ul> <li>If no arguments are specified then collection starts from <code>testpaths</code> (if configured in <code>pyproject.toml</code> or <code>pytest.ini</code>), or the current directory.</li> <li>Recurse into directories, unless they match <code>norecursedirs</code>.</li> <li>In those directories, search for <code>test_*.py</code> or <code>*_test.py</code> files.</li> <li>From those files, collect test items:<ul> <li>functions with <code>test</code> prefixed name. e.g., <code>test_is_valid</code>, etc.</li> <li>Methods with <code>test</code> prefixed name inside Classes with name <code>Test{ClassName}</code> without <code>__init__</code> method.</li> <li>Methods decorated with <code>@staticmethod</code> and <code>@classmethods</code> are also considered in classes with <code>Test</code> prefixed name and without <code>__init__</code>.</li> </ul> </li> </ul>"},{"location":"05-libraries/01-pytest/01-install-and-config/#pytest-configuration","title":"Pytest Configuration","text":"<p>To get help on command line options and values in INI-style configurations files by using the general help option:</p> <pre><code>pytest -h   # prints options _and_ config file settings\n</code></pre> <p>This will display command line and configuration file settings which were registered by installed plugins.</p> <ul> <li>We can specify pytest configurations in either <code>pytest.ini</code>, or <code>.pytest.ini</code> (hidden file), or <code>pyproject.toml</code> file.</li> <li> <p><code>pytest.ini</code> files take precedence over other files, even when empty.</p> </li> <li> <p>sample <code>pytest.ini</code> file</p> </li> </ul> <pre><code># pytest.ini or .pytest.ini\n[pytest]\nminversion = 6.0\naddopts = -ra -q\ntestpaths =\n    tests\n    integration\n</code></pre> <ul> <li>sample <code>pyproject.toml</code> pytest config</li> </ul> <pre><code># pyproject.toml\n[tool.pytest.ini_options]\nminversion = \"6.0\"\ntestpaths = [\n    \"tests\",\n]\nnorecursedirs = [\n    \".git\",\n    \".github\",\n    \"dist\",\n    \"build\",\n    \"docs\",\n]\naddopts = [\n    \"--strict-markers\",\n    \"--doctest-modules\",\n    \"--color=yes\",\n    \"--disable-pytest-warnings\",\n    \"--ignore=legacy/checkpoints\",\n]\nmarkers = [\n    \"cloud: Run the cloud tests for example\",\n]\nfilterwarnings = [\n    \"error::FutureWarning\",\n]\nxfail_strict = true\njunit_duration_report = \"call\"\n</code></pre> <p>Explanation of some pytest config options</p> <ul> <li><code>minversion = \"6.0\"</code> \u2192 Requires pytest version 6.0 or higher.  </li> <li><code>testpaths</code> \u2192 Specifies directories or files where pytest should look for tests, improving test discovery performance.</li> <li><code>norecursedirs</code> \u2192 Prevents pytest from searching for tests in specified directories.  </li> <li><code>addopts</code> \u2192 Additional command-line options for pytest execution.  <ul> <li><code>--strict-markers</code> \u2192 Enforces strict marker usage; unregistered markers cause errors.  </li> <li><code>--doctest-modules</code> \u2192 Runs doctests in all modules.  </li> <li><code>--color=yes</code> \u2192 Enables colored output in pytest results.  </li> <li><code>--disable-pytest-warnings</code> \u2192 Suppresses pytest-specific warnings.  </li> <li><code>--ignore=legacy/checkpoints</code> \u2192 Ignores the specified directory when discovering tests.  </li> </ul> </li> <li><code>markers</code> \u2192 Defines custom markers like <code>cloud</code> for categorizing tests.  </li> <li><code>filterwarnings</code> \u2192 Converts <code>FutureWarning</code> to an error, ensuring deprecated features are addressed.  </li> <li><code>xfail_strict = true</code> \u2192 Treats all <code>xfail</code> tests as failures if they unexpectedly pass.  </li> <li><code>junit_duration_report = \"call\"</code> \u2192 Includes test call durations in JUnit XML reports.</li> </ul>"},{"location":"05-libraries/01-pytest/01-install-and-config/#recommended-project-structure","title":"Recommended project structure","text":"<pre><code>pyproject.toml\nsrc/\n    mypkg/\n        __init__.py\n        app.py\n        view.py\ntests/\n    test_app.py\n    test_view.py\n    ...\n</code></pre> <p>To run tests:</p> <ul> <li>First install project in <code>editable mode.</code></li> </ul> <pre><code>pip install -e .\n</code></pre> <ul> <li>then, run tests</li> </ul> <pre><code>pytest # and provide options or use config file (pytest.ini or pyproject.toml)\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/","title":"Pytest Basic Usage","text":""},{"location":"05-libraries/01-pytest/02-basic-usage/#assert-that-something-is-true","title":"Assert that something is true","text":"<pre><code># content of test_sample.py\ndef func(x):\n    return x + 1\n\n\ndef test_answer():\n    assert func(3) == 5, \"some msgto be printed in the traceback if fails\"\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/#assert-that-a-certain-exception-is-raised","title":"Assert that a certain exception is raised","text":"<pre><code># content of test_sysexit.py\nimport pytest\n\n\ndef f():\n    raise SystemExit(1)\n\n\ndef test_mytest():\n    with pytest.raises(SystemExit):\n        f()\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/#matching-exception-messages","title":"Matching <code>Exception</code> messages","text":"<pre><code>import pytest\n\n\ndef myfunc():\n    raise ValueError(\"Exception 123 raised\")\n\n\ndef test_match():\n    with pytest.raises(ValueError, match=r\".* 123 .*\"):\n        myfunc()\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/#using-context-provided-by-raises","title":"Using <code>context</code> provided by <code>raises</code>","text":"<pre><code>def test_foo_not_implemented():\n    def foo():\n        raise NotImplementedError\n\n    with pytest.raises(RuntimeError) as excinfo:\n        foo()\n    assert excinfo.type is RuntimeError\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/#handling-exceptiongroup-in-pytest","title":"Handling <code>ExceptionGroup</code> in pytest","text":"<ul> <li>You can also use the context provided by raises to assert that an expected exception is part of a raised <code>ExceptionGroup</code>:</li> </ul> <pre><code># content of test_exceptiongroup.py\nimport pytest\n\n\ndef f():\n    raise ExceptionGroup(\n        \"Group message\",\n        [\n            RuntimeError(),\n        ],\n    )\n\n\ndef test_exception_in_group():\n    with pytest.raises(ExceptionGroup) as excinfo:\n        f()\n    assert excinfo.group_contains(RuntimeError)\n    assert not excinfo.group_contains(TypeError)\n</code></pre>"},{"location":"05-libraries/01-pytest/02-basic-usage/#group-multiple-tests-in-a-class","title":"Group multiple tests in a class","text":"<ul> <li>Class name should be prefixed with <code>Test</code>, and method names should be prefixed with <code>test</code>.</li> <li>No <code>__init__</code> method should be there.</li> </ul> <pre><code># content of test_class_demo.py\nclass TestClassDemoInstance:\n    value = 0\n\n    def test_one(self):\n        self.value = 1\n        assert self.value == 1\n\n    def test_two(self):\n        assert self.value == 1 # will fail, as each test run has unique instance\n</code></pre> <p>Grouping tests in class</p> <p>Inside classes, <code>each test has a unique instance of the class</code>.</p>"},{"location":"05-libraries/01-pytest/02-basic-usage/#xfail-mark-and-pytestraises","title":"<code>xfail mark</code> and <code>pytest.raises</code>","text":"<pre><code>def f():\n    raise IndexError()\n\n\n@pytest.mark.xfail(raises=IndexError)\ndef test_f():\n    f()\n</code></pre> <ul> <li>This will only \u201cxfail\u201d if the test fails by raising IndexError or subclasses.</li> </ul> <p><code>xfail</code> v/s <code>raises</code> So when to use which one?</p> <ul> <li>If there's an existing bug that is yet to be fixed, use <code>xfail</code>. It will help you in documenting unfixed bugs when you decide to fix.</li> <li><code>pytest.raises</code> is likely to be better for cases where you are testing exceptions your own code is deliberately raising, which is the majority of cases.</li> </ul>"},{"location":"05-libraries/01-pytest/03-fixtures/","title":"Fixtures","text":"<p>A fixture in testing is just preparation code that sets up everything needed before a test runs (e.g., creating a test database, initializing objects, or setting configurations).  </p> <p>We call it a fixture because it fixes or sets up a stable environment for tests, ensuring they always start with the same conditions.</p> <ul> <li>A function marked with <code>@pytest.fixture</code>, is a fixture.</li> <li><code>test functions</code> request <code>fixtures</code> they require by declaring them as arguments.</li> </ul> <p><code>conftest.py</code> file</p> <p>conftest.py is a special pytest configuration file that provides shared fixtures and hooks for tests without needing explicit imports.</p> <pre><code>@pytest.fixture\ndef my_num():\n    return 2\n\ndef test_num(my_num):\n    assert my_num == 2\n</code></pre>"},{"location":"05-libraries/01-pytest/03-fixtures/#fixtures-can-request-other-fixtures","title":"Fixtures can request other fixtures","text":"<pre><code># contents of test_append.py\nimport pytest\n\n\n# Arrange\n@pytest.fixture\ndef first_entry():\n    return \"a\"\n\n\n# Arrange\n@pytest.fixture\ndef order(first_entry):\n    return [first_entry]\n\n\ndef test_string(order):\n    # Act\n    order.append(\"b\")\n\n    # Assert\n    assert order == [\"a\", \"b\"]\n\n\ndef test_int(order):\n    # Act\n    order.append(2)\n\n    # Assert\n    assert order == [\"a\", 2]\n</code></pre>"},{"location":"05-libraries/01-pytest/03-fixtures/#autouse-fixtures-fixtures-you-dont-have-to-request","title":"Autouse fixtures (fixtures you don\u2019t have to request)","text":"<ul> <li>Sometimes you may want to have a fixture (or <code>even several</code>) that you know all your tests will depend on.</li> </ul> <pre><code>import pytest\n\n\n@pytest.fixture\ndef first_entry():\n    return \"a\"\n\n\n@pytest.fixture\ndef order(first_entry):\n    return []\n\n\n@pytest.fixture(autouse=True)\ndef append_first(order, first_entry):\n    return order.append(first_entry)\n\n\ndef test_string_only(order, first_entry):\n    assert order == [first_entry]\n\n\ndef test_string_and_int(order, first_entry):\n    order.append(2)\n    assert order == [first_entry, 2]\n</code></pre>"},{"location":"05-libraries/01-pytest/03-fixtures/#teardowncleanup-fixture-finalization","title":"Teardown/cleanup (fixture finalization)","text":"<ul> <li>In fixture, rather than <code>return</code>, use <code>yield</code>, after yielding, write cleanup code.</li> </ul> <pre><code># from lightning-ai/litdata/tests/conftest.py file\n\n@pytest.fixture(autouse=True)\ndef teardown_process_group():\n    \"\"\"Ensures distributed process group gets closed before the next test runs.\"\"\"\n    yield\n    if torch.distributed.is_available() and torch.distributed.is_initialized():\n        torch.distributed.destroy_process_group()\n</code></pre> <p>Fixture setup &amp; teardown</p> <p>Think of fixture function to be split in two parts. <code>setup | yield | teardown</code></p> <pre><code>@pytest.fixture\ndef my_fixt():\n    print(\"this is my setup code\")\n    yield {\"name\":\"deep\"} # or whatever you wish to return\n    print(\"this is my teardown code\")\n</code></pre>"},{"location":"05-libraries/01-pytest/03-fixtures/#scope-of-fixtures","title":"Scope of fixtures","text":"<ul> <li>Fixtures requiring network access depend on connectivity and are usually time-expensive to create.</li> <li>We can add a <code>scope=\"module\"</code> parameter to the <code>@pytest.fixture</code> invocation to cause a fixture function, so it will only be invoked once per test module (the default is to invoke once per test function).</li> <li>Multiple test functions in a test module will thus each receive the same fixture instance, thus saving time.</li> </ul> Scope detail function (default) the fixture is destroyed at the end of the test. class the fixture is destroyed during teardown of the last test in the class. module the fixture is destroyed during teardown of the last test in the module. package the fixture is destroyed during teardown of the last test in the package where the fixture is defined, including sub-packages and sub-directories within it. session the fixture is destroyed at the end of the test session. <pre><code>@pytest.fixture(scope=\"session\")\ndef smtp_connection():\n    # the returned fixture value will be shared for\n    # all tests requesting it\n    ...\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/","title":"Mark test functions with attributes","text":"<ul> <li>By using the <code>pytest.mark</code> helper you can easily set metadata on your test functions.</li> </ul>"},{"location":"05-libraries/01-pytest/04-markers/#some-common-markers","title":"Some common markers","text":"marker information usefixtures use fixtures on a test function or class filterwarnings filter certain warnings of a test function skip always skip a test function skipif skip a test function if a certain condition is met xfail produce an \u201cexpected failure\u201d outcome if a certain condition is met parameterize perform multiple calls to the same test function."},{"location":"05-libraries/01-pytest/04-markers/#usefixtures","title":"<code>usefixtures</code>","text":"<ul> <li>Sometimes test functions do not directly need access to a fixture object.</li> <li>So, rather than specifying in test function parameter, we simply mark it with <code>pytest.mark.usefixtures</code>.</li> </ul> <pre><code>@pytest.mark.usefixtures(\"fixture_one\", \"another_fixture\")\ndef test(): ...\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/#filterwarnings","title":"<code>filterwarnings</code>","text":"<ul> <li>You can use the <code>@pytest.mark.filterwarnings</code> mark to add warning filters to specific test items, allowing you to have finer control of which warnings should be captured at test, class or even module level:</li> </ul> <pre><code>import warnings\n\n\ndef api_v1():\n    warnings.warn(UserWarning(\"api v1, should use functions from v2\"))\n    return 1\n\n\n@pytest.mark.filterwarnings(\"ignore:api v1\")\ndef test_one():\n    assert api_v1() == 1\n</code></pre> <ul> <li>You can specify multiple filters with separate decorators:</li> </ul> <pre><code># Ignore \"api v1\" warnings, but fail on all other warnings\n@pytest.mark.filterwarnings(\"ignore:api v1\")\n@pytest.mark.filterwarnings(\"error\")\ndef test_one():\n    assert api_v1() == 1\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/#skip","title":"<code>skip</code>","text":"<p>The simplest way to skip a test function is to mark it with the skip decorator which may be passed an optional reason:</p> <pre><code>@pytest.mark.skip(reason=\"no way of currently testing this\")\ndef test_the_unknown(): ...\n</code></pre> <ul> <li>Alternatively, it is also possible to skip imperatively during test execution or setup by calling the pytest.skip(reason) function:</li> </ul> <pre><code>def test_function():\n    if not valid_config():\n        pytest.skip(\"unsupported configuration\")\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/#skipif","title":"<code>skipif</code>","text":"<p>If you wish to skip something conditionally then you can use skipif instead.</p> <pre><code>import sys\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"windows isn't supported\")\ndef test_dataset_for_text_tokens_with_large_num_chunks(tmpdir):\n    import resource\n\n    resource.setrlimit(resource.RLIMIT_NOFILE, (1024, 1024))\n\n    block_size = 1024\n    cache = Cache(input_dir=str(tmpdir), chunk_bytes=\"10KB\", item_loader=TokensLoader(block_size))\n\n    for i in range(10000):\n        text_ids = torch.randint(0, 10001, (torch.randint(100, 1001, (1,)).item(),)).numpy()\n        cache._add_item(i, text_ids)\n\n    cache.done()\n    cache.merge()\n\n    dataset = StreamingDataset(input_dir=str(tmpdir), item_loader=TokensLoader(block_size), shuffle=True)\n\n    for _ in dataset:\n        pass\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/#xfail","title":"<code>xfail</code>","text":"<ul> <li>You can use the xfail marker to indicate that you expect a test to fail</li> </ul> <pre><code>@pytest.mark.xfail\ndef test_function(): ...\n</code></pre> <ul> <li>Alternatively, you can also mark a test as XFAIL from within the test or its setup function imperatively</li> </ul> <pre><code>def test_function():\n    if not valid_config():\n        pytest.xfail(\"failing configuration (but should work)\")\n\n# ------\n\ndef test_function2():\n    import slow_module\n\n    if slow_module.slow_function():\n        pytest.xfail(\"slow_module taking too long\")\n</code></pre> <ul> <li><code>xfail</code> conditionally</li> </ul> <pre><code>@pytest.mark.xfail(sys.platform == \"win32\", reason=\"bug in a 3rd party library\")\ndef test_function(): ...\n</code></pre> <ul> <li><code>xfail</code> with a specific exception</li> </ul> <pre><code>@pytest.mark.xfail(raises=RuntimeError)\ndef test_function(): ...\n</code></pre> <ul> <li>If a test should be marked as xfail and reported as such but <code>should not be even executed</code>, use the <code>run</code> parameter as <code>False</code>:</li> </ul> <pre><code>@pytest.mark.xfail(run=False)\ndef test_function(): ...\n</code></pre> <p>!!! <code>strict=True</code> in <code>xfail</code>     - Both <code>XFAIL</code> and <code>XPASS</code> don\u2019t fail the test suite by default.     - With <code>strict=True</code>, <code>XPASS (\u201cunexpectedly passing\u201d)</code> results from this test to fail the test suite.</p> <pre><code>```python\n@pytest.mark.xfail(strict=True)\ndef test_function(): ...\n```\n</code></pre>"},{"location":"05-libraries/01-pytest/04-markers/#skipxfail-with-parametrize","title":"<code>Skip/xfail with parametrize</code>","text":"<ul> <li>It is possible to apply markers like skip and xfail to individual test instances when using parametrize:</li> </ul> <pre><code>import sys\n\nimport pytest\n\n\n@pytest.mark.parametrize(\n    (\"n\", \"expected\"),\n    [\n        (1, 2),\n        pytest.param(1, 0, marks=pytest.mark.xfail),\n        pytest.param(1, 3, marks=pytest.mark.xfail(reason=\"some bug\")),\n        (2, 3),\n        (3, 4),\n        (4, 5),\n        pytest.param(\n            10, 11, marks=pytest.mark.skipif(sys.version_info &gt;= (3, 0), reason=\"py2k\")\n        ),\n    ],\n)\ndef test_increment(n, expected):\n    assert n + 1 == expected\n</code></pre>"},{"location":"05-libraries/01-pytest/05-parameterize/","title":"Parameterize tests","text":""},{"location":"05-libraries/01-pytest/05-parameterize/#simple-usage","title":"Simple Usage","text":"<ul> <li>pytest allows to easily parametrize test functions using <code>@pytest.mark.parametrize</code>.</li> <li>We can also set marks for individual parameterize test.</li> </ul> <pre><code># content of test_pytest_param_example.py\nimport pytest\n\n\n@pytest.mark.parametrize(\n    \"test_input,expected\",\n    [\n        (\"3+5\", 8),\n        pytest.param(\"1+7\", 8, marks=pytest.mark.basic),\n        pytest.param(\"2+4\", 6, marks=pytest.mark.basic, id=\"basic_2+4\"),\n        pytest.param(\n            \"6*9\", 42, marks=[pytest.mark.basic, pytest.mark.xfail], id=\"basic_6*9\"\n        ),\n    ],\n)\ndef test_eval(test_input, expected):\n    assert eval(test_input) == expected\n</code></pre>"},{"location":"05-libraries/01-pytest/05-parameterize/#chaining-multiple-pytestmarkparametrize","title":"Chaining multiple <code>@pytest.mark.parametrize</code>","text":"<pre><code># taken from litdata tests\n\n@pytest.mark.parametrize(\"drop_last\", [False, True])\n@pytest.mark.parametrize(\n    \"compression\",\n    [\n        pytest.param(None),\n        pytest.param(\"zstd\", marks=pytest.mark.skipif(condition=not _ZSTD_AVAILABLE, reason=\"Requires: ['zstd']\")),\n    ],\n)\n@pytest.mark.timeout(60)\ndef test_streaming_dataset_distributed_full_shuffle_odd(drop_last, tmpdir, compression):\n    ... # test body\n</code></pre>"},{"location":"05-libraries/01-pytest/05-parameterize/#parametrizing-conditional-raising","title":"Parametrizing conditional raising","text":"<pre><code>from contextlib import nullcontext\n\nimport pytest\n\n\n@pytest.mark.parametrize(\n    \"example_input,expectation\",\n    [\n        (3, nullcontext(2)),\n        (2, nullcontext(3)),\n        (1, nullcontext(6)),\n        (0, pytest.raises(ZeroDivisionError)),\n    ],\n)\ndef test_division(example_input, expectation):\n    \"\"\"Test how much I know division.\"\"\"\n    with expectation as e:\n        assert (6 / example_input) == e\n</code></pre> <ul> <li>To use ValueError with <code>match</code>: <code>pytest.raises(ValueError, match=\"The provided\")</code></li> </ul>"},{"location":"05-libraries/01-pytest/05-parameterize/#test-ids-in-parameterize","title":"test <code>IDs</code> in parameterize","text":"<ul> <li>pytest will build a string that is the test ID for each set of values in a parametrized test.</li> </ul> <pre><code># content of test_time.py\n\nfrom datetime import datetime, timedelta\n\nimport pytest\n\ntestdata = [\n    (datetime(2001, 12, 12), datetime(2001, 12, 11), timedelta(1)),\n    (datetime(2001, 12, 11), datetime(2001, 12, 12), timedelta(-1)),\n]\n\n\n@pytest.mark.parametrize(\"a,b,expected\", testdata)\ndef test_timedistance_v0(a, b, expected):\n    diff = a - b\n    assert diff == expected\n\n\n@pytest.mark.parametrize(\"a,b,expected\", testdata, ids=[\"forward\", \"backward\"])\ndef test_timedistance_v1(a, b, expected):\n    diff = a - b\n    assert diff == expected\n\n\ndef idfn(val):\n    if isinstance(val, (datetime,)):\n        # note this wouldn't show any hours/minutes/seconds\n        return val.strftime(\"%Y%m%d\")\n\n\n@pytest.mark.parametrize(\"a,b,expected\", testdata, ids=idfn)\ndef test_timedistance_v2(a, b, expected):\n    diff = a - b\n    assert diff == expected\n\n\n@pytest.mark.parametrize(\n    \"a,b,expected\",\n    [\n        pytest.param(\n            datetime(2001, 12, 12), datetime(2001, 12, 11), timedelta(1), id=\"forward\"\n        ),\n        pytest.param(\n            datetime(2001, 12, 11), datetime(2001, 12, 12), timedelta(-1), id=\"backward\"\n        ),\n    ],\n)\ndef test_timedistance_v3(a, b, expected):\n    diff = a - b\n    assert diff == expected\n</code></pre> <ul> <li>In <code>test_timedistance_v0</code>, we let pytest generate the test IDs.</li> <li>In <code>test_timedistance_v1</code>, we specified ids as a list of strings which were used as the test IDs. These are succinct, but can be a pain to maintain.</li> <li>In <code>test_timedistance_v2</code>, we specified ids as a function that can generate a string representation to make part of the test ID.</li> </ul> <ul> <li>generated IDs for above parameterized tests:</li> </ul> <pre><code>$ pytest test_time.py --collect-only\n=========================== test session starts ============================\nplatform linux -- Python 3.x.y, pytest-8.x.y, pluggy-1.x.y\nrootdir: /home/sweet/project\ncollected 8 items\n\n&lt;Dir parametrize.rst-205&gt;\n  &lt;Module test_time.py&gt;\n    &lt;Function test_timedistance_v0[a0-b0-expected0]&gt;\n    &lt;Function test_timedistance_v0[a1-b1-expected1]&gt;\n    &lt;Function test_timedistance_v1[forward]&gt;\n    &lt;Function test_timedistance_v1[backward]&gt;\n    &lt;Function test_timedistance_v2[20011212-20011211-expected0]&gt;\n    &lt;Function test_timedistance_v2[20011211-20011212-expected1]&gt;\n    &lt;Function test_timedistance_v3[forward]&gt;\n    &lt;Function test_timedistance_v3[backward]&gt;\n\n======================== 8 tests collected in 0.12s ========================\n</code></pre> <ul> <li>To run specific parameterized test with its <code>ID</code>:</li> </ul> <pre><code>pytest -k \"forward\"\n</code></pre>"},{"location":"05-libraries/01-pytest/06-tmppath/","title":"<code>tmppath</code> fixture","text":"<ul> <li>You can use the <code>tmp_path</code> fixture which will provide <code>a temporary directory unique to each test function</code>.</li> <li><code>tmp_path</code> is a <code>pathlib.Path</code> object</li> </ul> <pre><code># content of test_tmp_path.py\nCONTENT = \"content\"\n\n\ndef test_create_file(tmp_path):\n    d = tmp_path / \"sub\"\n    d.mkdir()\n    p = d / \"hello.txt\"\n    p.write_text(CONTENT, encoding=\"utf-8\")\n    assert p.read_text(encoding=\"utf-8\") == CONTENT\n    assert len(list(tmp_path.iterdir())) == 1\n    assert 0\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/","title":"Monkeypatch &amp; Mocking","text":"<p>What does Monkeypatch even mean?</p> <ul> <li>Modifying properties/methods at runtime without changing the actual code logic.</li> </ul> <pre><code>from SomeOtherProduct.SomeModule import SomeClass\n\ndef speak(self):\n    return \"ook ook eee eee eee!\"\n\nSomeClass.speak = speak\n</code></pre> <ul> <li>Sometimes tests need to invoke functionality which depends on global settings or which invokes code which cannot be easily tested such as network access.</li> <li>The monkeypatch fixture helps you to safely set/delete an attribute, dictionary item or environment variable, or to modify sys.path for importing.</li> </ul>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-fixture","title":"<code>monkeypatch</code> fixture","text":"<p>monkeypatch fixture</p> <p>Modifying the behavior of a function or the property of a class for a test</p> <ul> <li>monkeypatch.setattr(obj, name, value, raising=True)</li> <li>monkeypatch.delattr(obj, name, raising=True)</li> </ul> <p>Modifying the values of dictionaries</p> <ul> <li>monkeypatch.setitem(mapping, name, value)</li> <li>monkeypatch.delitem(obj, name, raising=True)</li> </ul> <p>Modifying env variables. </p> <p>With <code>prepend = \"some_val\"</code>, the env-var won't be overwritten, but just <code>value+prepend_str+old_env_value</code></p> <p>With <code>prepend=None</code>, it simply replaces the old env value with new value. </p> <ul> <li>monkeypatch.setenv(name, value, prepend=None)</li> <li>monkeypatch.delenv(name, raising=True)</li> </ul> <ul> <li>monkeypatch.syspath_prepend(path)</li> <li>monkeypatch.chdir(path)</li> <li>monkeypatch.context()</li> </ul> <ul> <li><code>All modifications will be undone after the requesting test function or fixture has finished</code>.</li> <li>The <code>raising</code> parameter determines if a <code>KeyError</code> or <code>AttributeError</code> will be raised if the target of the set/deletion operation does not exist.</li> </ul> <pre><code>import pytest\n\nclass MyClass:\n    value = 42\n\ndef test_patch(monkeypatch):\n    monkeypatch.setattr(MyClass, \"value\", 100)  # Works fine\n    monkeypatch.setattr(MyClass, \"non_existent\", 200, raising=False)  # No error\n    # monkeypatch.setattr(MyClass, \"non_existent\", 200, raising=True)  # Raises AttributeError\n</code></pre> <ul> <li>If <code>raising=True (default)</code>, pytest will raise an error if the attribute does not already exist in the target object.</li> </ul>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-functions","title":"Monkeypatch <code>functions</code>","text":"<pre><code># contents of test_module.py with source code and the test\nfrom pathlib import Path\n\n\ndef getssh():\n    \"\"\"Simple function to return expanded homedir ssh path.\"\"\"\n    return Path.home() / \".ssh\"\n\n\ndef test_getssh(monkeypatch):\n    # mocked return function to replace Path.home\n    # always return '/abc'\n    def mockreturn():\n        return Path(\"/abc\")\n\n    # Application of the monkeypatch to replace Path.home\n    # with the behavior of mockreturn defined above.\n    monkeypatch.setattr(Path, \"home\", mockreturn)\n\n    # Calling getssh() will use mockreturn in place of Path.home\n    # for this test with the monkeypatch.\n    x = getssh()\n    assert x == Path(\"/abc/.ssh\")\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-returned-objects","title":"Monkeypatch <code>returned objects</code>","text":"<pre><code># contents of test_app.py, a simple test for our API retrieval\n# import requests for the purposes of monkeypatching\nimport requests\n\n# our app.py that includes the get_json() function\n# this is the previous code block example\nimport app\n\n\n# custom class to be the mock return value\n# will override the requests.Response returned from requests.get\nclass MockResponse:\n    # mock json() method always returns a specific testing dictionary\n    @staticmethod\n    def json():\n        return {\"mock_key\": \"mock_response\"}\n\n\ndef test_get_json(monkeypatch):\n    # Any arguments may be passed and mock_get() will always return our\n    # mocked object, which only has the .json() method.\n    def mock_get(*args, **kwargs):\n        return MockResponse()\n\n    # apply the monkeypatch for requests.get to mock_get\n    monkeypatch.setattr(requests, \"get\", mock_get)\n\n    # app.get_json, which contains requests.get, uses the monkeypatch\n    result = app.get_json(\"https://fakeurl\")\n    assert result[\"mock_key\"] == \"mock_response\"\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-context","title":"Monkeypatch <code>context</code>","text":"<pre><code>import functools\n\n\ndef test_partial(monkeypatch):\n    with monkeypatch.context() as m:\n        m.setattr(functools, \"partial\", 3)\n        assert functools.partial == 3\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-dictionaries","title":"Monkeypatch <code>dictionaries</code>","text":"<pre><code># contents of app.py to generate a simple connection string\nDEFAULT_CONFIG = {\"user\": \"user1\", \"database\": \"db1\"}\n\n\ndef create_connection_string(config=None):\n    \"\"\"Creates a connection string from input or defaults.\"\"\"\n    config = config or DEFAULT_CONFIG\n    return f\"User Id={config['user']}; Location={config['database']};\"\n\n# ============================\n\n# contents of test_app.py\n# app.py with the connection string function (prior code block)\nimport app\n\n\ndef test_connection(monkeypatch):\n    # Patch the values of DEFAULT_CONFIG to specific\n    # testing values only for this test.\n    monkeypatch.setitem(app.DEFAULT_CONFIG, \"user\", \"test_user\")\n    monkeypatch.setitem(app.DEFAULT_CONFIG, \"database\", \"test_db\")\n\n    # expected result based on the mocks\n    expected = \"User Id=test_user; Location=test_db;\"\n\n    # the test uses the monkeypatched dictionary settings\n    result = app.create_connection_string()\n    assert result == expected\n\ndef test_missing_user(monkeypatch):\n    # patch the DEFAULT_CONFIG t be missing the 'user' key\n    monkeypatch.delitem(app.DEFAULT_CONFIG, \"user\", raising=False)\n\n    # Key error expected because a config is not passed, and the\n    # default is now missing the 'user' entry.\n    with pytest.raises(KeyError):\n        _ = app.create_connection_string()\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-env-variables","title":"Monkeypatch <code>env variables</code>","text":"<pre><code># contents of our original code file e.g. code.py\nimport os\n\n\ndef get_os_user_lower():\n    \"\"\"Simple retrieval function.\n    Returns lowercase USER or raises OSError.\"\"\"\n    username = os.getenv(\"USER\")\n\n    if username is None:\n        raise OSError(\"USER environment is not set.\")\n\n    return username.lower()\n\n# ========================\n\n# contents of our test file e.g. test_code.py\nimport pytest\n\n\ndef test_upper_to_lower(monkeypatch):\n    \"\"\"Set the USER env var to assert the behavior.\"\"\"\n    monkeypatch.setenv(\"USER\", \"TestingUser\")\n    assert get_os_user_lower() == \"testinguser\"\n\n\ndef test_raise_exception(monkeypatch):\n    \"\"\"Remove the USER env var and assert OSError is raised.\"\"\"\n    monkeypatch.delenv(\"USER\", raising=False)\n\n    with pytest.raises(OSError):\n        _ = get_os_user_lower()\n</code></pre>"},{"location":"05-libraries/01-pytest/07-monkeypatch-mock/#monkeypatch-as-fixtures","title":"Monkeypatch as <code>fixtures</code>","text":"<ul> <li>Using monkeypatch code in fixtures fixes the hassle to write it everytime you need it.</li> </ul> <pre><code>import pytest\nimport os\n\n# A simple test where we patch the environment variable\n@pytest.fixture\ndef mock_env(monkeypatch):\n    monkeypatch.setenv(\"MY_VAR\", \"fake_value\")\n\ndef test_env_var(mock_env):\n    assert os.getenv(\"MY_VAR\") == \"fake_value\"\n</code></pre> <ul> <li>By default, <code>fixtures have a function scope</code>, meaning they are created and destroyed for each test.</li> <li>You can adjust the scope if you want them to persist across multiple tests (e.g., using <code>scope=\"module\"</code>).</li> </ul> <p>For details: check here</p>"},{"location":"05-libraries/01-pytest/08-unittest-mock/","title":"unittest.mock","text":"<ul> <li>The unittest library is part of the <code>standard library</code> but is often used together with pytest.</li> <li><code>unittest.mock</code> provides us with 3 most often used class and decorator.</li> <li><code>Mock</code>, <code>MagicMock</code> and <code>@patch</code>.</li> </ul>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#mock","title":"<code>Mock</code>","text":"<ul> <li><code>Mock</code> are <code>callable</code> and <code>create attributes as new mocks when you access them</code>.</li> <li>Mocks record how you use them, allowing you to make assertions about what your code has done to them.</li> <li> <p>We can check if, <code>mock was called</code>, was <code>called only once</code>, was <code>called with some args</code>, was <code>never called</code>, etc.</p> </li> <li> <p>Refer here for the whole list.</p> </li> </ul> <pre><code>from unittest.mock import Mock\n\nm = Mock()\n\nm()\n\nm.assert_called()\nm.assert_called_once()\n\nm(1, 2, 3, test='wow')\nm.assert_called_with(1, 2, 3, test='wow')\n\nm('foo', bar='baz')\nm.assert_called_once_with('other', bar='values')\n\nm(1, 2, arg='thing')\nm.assert_any_call(1, 2, arg='thing')\n</code></pre> <ul> <li>On mock object, we can call arbitrary method.</li> </ul> <pre><code>from unittest.mock import Mock\n\nm = Mock()\nm.meow()\nm.meow.bhow()\n</code></pre> <p>Default Mock return value: <code>sentinel.DEFAULT</code></p> <p>When you call a mock object, it returns a DEFAULT which is <code>sentinel.DEFAULT</code>. It can be used by side_effect functions to indicate that the normal return value should be used.</p> <ul> <li>But, we can also specify a <code>fixed return value</code>.</li> </ul> <pre><code>from unittest.mock import Mock\n\nm = Mock(return_value=5)\n\nfor _ in range(50):\n    m() # 5\n</code></pre> <ul> <li>Mock object have a side_effect property, which if is a <code>function, is called everytime the mock object is called</code>.</li> </ul> <pre><code>from unittest.mock import Mock\n\ndef some_fn(self):\n    return 5\n\nm = Mock()\n\nm() # senitnel.DEFAULT\n\nm.side_effect = some_fn\n\nm() # 5\n</code></pre> <ul> <li>We can also specify it in constructor.</li> </ul> <pre><code>m = Mock(side_effect = some_fn)\n</code></pre> <ul> <li>If <code>side_effect</code> is a list/iterable, each function call returns the first element from the list, and removes it. When all elements are exhausted, it throws <code>StopIteration</code> error on further calling.</li> </ul> <pre><code>from unittest.mock import Mock\n\nm = Mock(side_effect = [5,4,3,2,1])\n\nfor _ in range(6):\n    print(m()) # [5,4,3,2,1, StopIteration error]\n</code></pre> <p>Note</p> <p><code>side_effect</code> takes precedence over <code>return_value</code>.</p>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#magicmock","title":"MagicMock","text":"<ul> <li><code>MagicMock</code> is a superset (derived class) of Mock class. It has all the features as <code>Mock</code> class has, but also implements many <code>magic methods</code>, like:</li> </ul> <pre><code>__hash__, __sizeof__, __repr__ and __str__\n\n__round__, __floor__, __trunc__ and __ceil__\n\nComparisons: __lt__, __gt__, __le__, __ge__, __eq__ and __ne__\n\nContainer methods: __getitem__, __setitem__, __delitem__, __contains__, __len__, __iter__, __reversed__ and __missing__\n\nContext manager: __enter__, __exit__, __aenter__ and __aexit__\n\nUnary numeric methods: __neg__, __pos__ and __invert__\n\nThe numeric methods (including right hand and in-place variants): __add__, __sub__, __mul__, __matmul__, __truediv__, __floordiv__, __mod__, __divmod__, __lshift__, __rshift__, __and__, __xor__, __or__, and __pow__\n\nNumeric conversion methods: __complex__, __int__, __float__ and __index__\n\nDescriptor methods: __get__, __set__ and __delete__\n\nPickling: __reduce__, __reduce_ex__, __getinitargs__, __getnewargs__, __getstate__ and __setstate__\n\nFile system path representation: __fspath__\n\nAsynchronous iteration methods: __aiter__ and __anext__\n</code></pre> <ul> <li>So, if you want to be on safer side, and don't want to implement them for every Mock object, directly use <code>MagicMock</code>.</li> </ul> <p><code>MagicMock</code> v/s <code>Mock</code></p> <ul> <li>With <code>Mock</code> you can mock magic methods but you have to define them.</li> <li><code>MagicMock</code> has \"default implementations of most of the magic methods.\".</li> <li>If you don't need to test any magic methods, <code>Mock</code> is adequate and doesn't bring a lot of extraneous things into your tests.</li> <li>If you need to test a lot of magic methods <code>MagicMock</code> will save you some time (and less bloated).</li> </ul>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#patch-decorators","title":"<code>patch</code> decorators","text":"<ul> <li>The patch decorators are used for patching objects only within the scope of the function they decorate.</li> <li>They automatically handle the unpatching for you, even if exceptions are raised.</li> <li>All of these functions can also be used in with statements or as class decorators.</li> </ul>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#patch","title":"<code>@patch()</code>","text":"<ul> <li><code>patch</code> decorator can be used to modify some <code>target</code> temporarily.</li> <li>Pass in the path to <code>target</code>. <code>target</code> should be a string in the form <code>package.module.ClassName</code>.</li> <li> <p>The <code>target</code> is imported and the specified object replaced with the new object, so the target must be importable from the environment you are calling patch() from. The target is imported when the decorated function is executed, not at decoration time.</p> </li> <li> <p>You can either specify a <code>patched value</code>, or by default it will be a <code>Mock object</code>.</p> </li> <li>The function, if wants to access mock object, need to specify a parameter in reverse order of <code>@patch</code> chains.</li> </ul> <pre><code>@patch('__main__.SomeClass2')\n@patch('__main__.SomeClass1')\ndef function(normal_argument, mock_class1, mock_class2):\n    print(mock_class1 is SomeClass1)\n    print(mock_class2 is SomeClass2)\n\nfunction(None)\n</code></pre> <ul> <li>To patch with some value:</li> </ul> <pre><code>@patch(\"litdata.streaming.downloader._GOOGLE_STORAGE_AVAILABLE\", True)\ndef test_gcp_downloader(tmpdir, monkeypatch):\n    ... # you code\n</code></pre>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#patchobject","title":"<code>@patch.object</code>","text":"<ul> <li>Very similar, but for class methods.</li> <li>First parameter: target, second parameter: attribute.</li> </ul> <pre><code>@patch.object(SomeClass, 'class_method')\ndef test(mock_method):\n    SomeClass.class_method(3)\n    mock_method.assert_called_with(3)\n\ntest()\n</code></pre>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#patchdict","title":"<code>@patch.dict</code>","text":"<ul> <li> <p>Patch a dictionary, or dictionary like object, and restore the dictionary to its original state after the test.</p> </li> <li> <p>If <code>clear is true</code>, then the <code>dictionary will be cleared</code> before the new values are set.</p> </li> </ul> <pre><code>foo = {}\n@patch.dict(foo, {'newkey': 'newvalue'})\ndef test():\n    assert foo == {'newkey': 'newvalue'}\n\ntest()\nassert foo == {}\n</code></pre>"},{"location":"05-libraries/01-pytest/08-unittest-mock/#mocking-a-library-even-if-its-not-available","title":"Mocking a library, even if it's not available","text":"<ul> <li>Create a <code>fixture</code> that create a ModuleType object, and monkeypatch to <code>sys.modules</code>.</li> </ul> <pre><code>import pytest\nimport sys\nfrom types import ModuleType\n\n\n@pytest.fixture\ndef google_mock(monkeypatch):\n    google = ModuleType(\"google\")\n    monkeypatch.setitem(sys.modules, \"google\", google)\n    google_cloud = ModuleType(\"cloud\")\n    monkeypatch.setitem(sys.modules, \"google.cloud\", google_cloud)\n    google_cloud_storage = ModuleType(\"storage\")\n    monkeypatch.setitem(sys.modules, \"google.cloud.storage\", google_cloud_storage)\n    google.cloud = google_cloud\n    google.cloud.storage = google_cloud_storage\n    return google\n</code></pre> <ul> <li>Use the fixture, and make module a <code>Mock</code> object</li> </ul> <pre><code>@mock.patch(\"litdata.streaming.downloader._GOOGLE_STORAGE_AVAILABLE\", True)\ndef test_gcp_downloader(tmpdir, monkeypatch, google_mock):\n    # Create mock objects\n    mock_client = MagicMock()\n    mock_bucket = MagicMock()\n    mock_blob = MagicMock()\n    mock_blob.download_to_filename = MagicMock()\n\n    # Patch the storage client to return the mock client\n    google_mock.cloud.storage.Client = MagicMock(return_value=mock_client)\n\n    # Configure the mock client to return the mock bucket and blob\n    mock_client.bucket = MagicMock(return_value=mock_bucket)\n    mock_bucket.blob = MagicMock(return_value=mock_blob)\n\n    # Initialize the downloader\n    storage_options = {\"project\": \"DUMMY_PROJECT\"}\n    downloader = GCPDownloader(\"gs://random_bucket\", tmpdir, [], storage_options)\n    local_filepath = os.path.join(tmpdir, \"a.txt\")\n    downloader.download_file(\"gs://random_bucket/a.txt\", local_filepath)\n\n    # Assert that the correct methods were called\n    google_mock.cloud.storage.Client.assert_called_with(**storage_options)\n    mock_client.bucket.assert_called_with(\"random_bucket\")\n    mock_bucket.blob.assert_called_with(\"a.txt\")\n    mock_blob.download_to_filename.assert_called_with(local_filepath)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/","title":"NumPy - Numerical Python","text":""},{"location":"05-libraries/02-common-libraries/01-numpy/#installation","title":"Installation","text":"<pre><code>pip install numpy\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#creating-arrays","title":"Creating Arrays","text":"<pre><code>import numpy as np\n\na = np.array([1, 2, 3])               # 1D array\nb = np.array([[1, 2], [3, 4]])        # 2D array\n\nnp.zeros((2, 3))                      # All zeros\nnp.ones((3, 3))                       # All ones\nnp.eye(3)                             # Identity matrix\nnp.arange(0, 10, 2)                   # [0, 2, 4, 6, 8]\nnp.linspace(0, 1, 5)                  # [0. , 0.25, 0.5 , 0.75, 1. ]\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#array-operations","title":"Array Operations","text":"<pre><code>a + b      # Element-wise addition\na * 2      # Scalar multiplication\na @ b      # Matrix multiplication (or np.dot(a, b))\na.T        # Transpose\na.mean()   # Mean of all elements\na.sum()    # Sum of all elements\na.shape    # Shape of array\na.reshape((2, 3))  # Reshape\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#npconcatenate","title":"<code>np.concatenate</code>","text":"<pre><code>a = np.array([[1, 2], [3, 4]])\nb = np.array([[5, 6]])\n\nnp.concatenate((a, b), axis=0)  # Vertical stack\nnp.concatenate((a.T, b.T), axis=1)  # Horizontal stack\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#npcumsum-cumulative-sum","title":"<code>np.cumsum</code> (Cumulative Sum)","text":"<pre><code>a = np.array([1, 2, 3, 4])\nnp.cumsum(a)  # [ 1  3  6 10 ]\n\nb = np.array([[1, 2], [3, 4]])\nnp.cumsum(b, axis=0)\n# [[1 2]\n#  [4 6]]\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#indexing-slicing","title":"Indexing &amp; Slicing","text":"<pre><code>a[0]           # First element\na[1:3]         # Slice\na[:, 1]        # All rows, 2nd column\na[::2]         # Every other element\na[a &gt; 2]       # Boolean masking\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#random","title":"Random","text":"<pre><code>np.random.seed(42)                # For reproducibility\nnp.random.rand(3, 3)              # Uniform [0, 1)\nnp.random.randn(3, 3)             # Normal distribution\nnp.random.randint(0, 10, (2, 3))  # Random ints in [0, 10)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/01-numpy/#useful-utilities","title":"Useful Utilities","text":"<pre><code>np.unique(a)       # Unique values\nnp.clip(a, 0, 1)   # Clamp values to [0, 1]\nnp.sort(a)         # Sort\nnp.argmax(a)       # Index of max\nnp.isnan(a)        # Check NaNs\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/","title":"OpenCV (cv2) - Computer Vision Library","text":""},{"location":"05-libraries/02-common-libraries/04-opencv/#installation","title":"Installation","text":"<pre><code>pip install opencv-python\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#load-display-an-image","title":"Load &amp; display an image","text":"<pre><code>import cv2\n\n# Load image (in BGR format by default)\nimg = cv2.imread('path/to/image.jpg')\n\n# Display the image in a window\ncv2.imshow('Image', img)\ncv2.waitKey(0) # how many milliseconds to wait for a key press (0 = wait indefinitely)\ncv2.destroyAllWindows()\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#convert-bgr-to-rgb-or-grayscale","title":"Convert BGR to RGB or Grayscale","text":"<pre><code># Convert BGR to RGB (e.g., for plotting with matplotlib)\nrgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Convert to grayscale\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#resize-reshape","title":"Resize &amp; reshape","text":"<pre><code># Resize to 256x256\nresized = cv2.resize(img, (256, 256))\n\n# Reshape to 1D array (not usually needed unless flattening)\nflattened = img.reshape(-1)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#blur-smoothing","title":"Blur &amp; smoothing","text":"<pre><code># Gaussian blur\nblurred = cv2.GaussianBlur(img, (5, 5), 0)\n\n# Median blur\nmedian = cv2.medianBlur(img, 5)\n\n# Bilateral filter (preserves edges)\nbilateral = cv2.bilateralFilter(img, 9, 75, 75)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#basic-transformations","title":"Basic transformations","text":"<pre><code># Flip image (0 = vertical, 1 = horizontal, -1 = both)\nflipped = cv2.flip(img, 1)\n\n# Rotate image 90 degrees clockwise\nrotated = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n\n# Crop (slicing)\ncropped = img[50:200, 100:300]\n</code></pre>"},{"location":"05-libraries/02-common-libraries/04-opencv/#save-an-image","title":"Save an image","text":"<pre><code>cv2.imwrite(\"output.jpg\", img)\n</code></pre>"},{"location":"05-libraries/02-common-libraries/05-pillow/","title":"Pillow (PIL fork) - Python Imaging Library","text":""},{"location":"05-libraries/02-common-libraries/05-pillow/#installation","title":"Installation","text":"<pre><code>pip install Pillow\n</code></pre>"},{"location":"05-libraries/02-common-libraries/05-pillow/#loading-showing-an-image","title":"Loading &amp; showing an Image","text":"<pre><code>from PIL import Image\n# Load an image from a file\nimage = Image.open('path/to/image.jpg')\n# Display the image\nimage.show()\n</code></pre>"},{"location":"05-libraries/02-common-libraries/05-pillow/#get-bytes-of-the-image","title":"Get bytes of the image","text":"<pre><code>from PIL import Image\nimport io\n\n# Load the image\nimg = Image.open(\"your_image.jpg\")\n\n# Save it into a bytes buffer\nbuffer = io.BytesIO()\nimg.save(buffer, format=\"JPEG\")  # or \"PNG\", depending on your image\n\n# Get the raw bytes\nimage_bytes = buffer.getvalue()\n\n# Print the bytes (optional: limit how many you print)\nprint(image_bytes[:100])  # prints first 100 bytes for sanity\n</code></pre>"},{"location":"05-libraries/02-common-libraries/05-pillow/#create-a-random-dummy-image","title":"Create a random dummy image","text":"<pre><code>from PIL import Image\nimport numpy as np\n\n# Generate random RGB pixel data\nrandom_pixels = np.random.randint(0, 256, (128, 128, 3), dtype=np.uint8)\n\n# Convert to a PIL Image\nimg = Image.fromarray(random_pixels, 'RGB')\n\n# Show the image (or save it if you want)\nimg.show()\n# img.save(\"dummy_image.png\")\n</code></pre>"}]}